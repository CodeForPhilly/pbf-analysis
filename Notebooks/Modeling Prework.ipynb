{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Philly Bail Fund\n",
    "## Analysis of factors related to Bail Amounts\n",
    "\n",
    "For more details, see the github repo: https://github.com/CodeForPhilly/pbf-analysis\n",
    "\n",
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard Imports - Sorry PEP8 fans, do not look below\n",
    "import pandas as pd, numpy as np, os, re, json, pickle, math\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "## Specific Imports\n",
    "import hashlib\n",
    "\n",
    "# frameworks\n",
    "from sklearn.model_selection import GroupKFold, KFold\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "# feat engineering\n",
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# modeling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# validation and scoring\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "### Display options for notebooks\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 25)\n",
    "\n",
    "### set path directories\n",
    "curr_dir = Path(os.getcwd())\n",
    "#print('Current Directory is: ', str(curr_dir))\n",
    "data_dir = Path(curr_dir.parents[0] / 'Data/')\n",
    "artifacts_dir = Path(curr_dir / 'artifacts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Common project specific variables\n",
    "FILENAME = '0c_distinct_dockets.csv'  # original data\n",
    "TARGET_VARIABLE_NAME = 'bail_amount'\n",
    "HOLDOUT_INDICATOR_NAME = 'holdout_ind'\n",
    "HOLDOUT_SIZE = 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to reduce memory footprint of the dataframe\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    import numpy as np\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: \n",
    "        print('Mem. usage decreased to {:5.2f} MB ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import\n",
    "\n",
    "Also, check a hash to see if this file has changed since this code was written. If it changes, someone should review this notebook to make sure that the code still works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOCKSIZE = 65536\n",
    "hasher = hashlib.md5()\n",
    "with open(Path(data_dir) / FILENAME, 'rb') as afile:\n",
    "    buf = afile.read(BLOCKSIZE)\n",
    "    while len(buf) > 0:\n",
    "        hasher.update(buf)\n",
    "        buf = afile.read(BLOCKSIZE)\n",
    "        \n",
    "filehash = hasher.hexdigest()\n",
    "\n",
    "with open(Path(artifacts_dir) / 'data_file_hash.txt', 'rb') as f:\n",
    "    checkhash = pickle.load(f)\n",
    "    \n",
    "if filehash != checkhash:\n",
    "    print(\"!! Warning !! The file is different than when this code was last updated. \\nProceed with caution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "UPDATE_HASH_FLAG = False\n",
    "\n",
    "if UPDATE_HASH_FLAG==True:\n",
    "    with open(Path(artifacts_dir) / 'data_file_hash.txt', 'wb') as f:\n",
    "        pickle.dump(filehash, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>docket_number</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>charge</th>\n",
       "      <th>represented_by</th>\n",
       "      <th>bail_type</th>\n",
       "      <th>bail_status</th>\n",
       "      <th>bail_amount</th>\n",
       "      <th>outstanding_bail_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>27.0</td>\n",
       "      <td>Philadelphia, PA 19141</td>\n",
       "      <td>MC-51-CR-0011746-2020</td>\n",
       "      <td>2020-06-16 00:37:00+00:00</td>\n",
       "      <td>DUI: Gen Imp/Inc of Driving Safely - 1st Off</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Posted</td>\n",
       "      <td>ROR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4538</th>\n",
       "      <td>44.0</td>\n",
       "      <td>Philadelphia, PA 19124</td>\n",
       "      <td>MC-51-CR-0011747-2020</td>\n",
       "      <td>2020-06-16 00:41:00+00:00</td>\n",
       "      <td>Verify Address or Photographed as Required</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Set</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>50000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Philadelphia, PA 19142</td>\n",
       "      <td>MC-51-CR-0011743-2020</td>\n",
       "      <td>2020-06-16 00:52:00+00:00</td>\n",
       "      <td>Criminal Mischief</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Posted</td>\n",
       "      <td>ROR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age                 address          docket_number  \\\n",
       "id                                                          \n",
       "3909  27.0  Philadelphia, PA 19141  MC-51-CR-0011746-2020   \n",
       "4538  44.0  Philadelphia, PA 19124  MC-51-CR-0011747-2020   \n",
       "120   24.0  Philadelphia, PA 19142  MC-51-CR-0011743-2020   \n",
       "\n",
       "                   filing_date                                        charge  \\\n",
       "id                                                                             \n",
       "3909 2020-06-16 00:37:00+00:00  DUI: Gen Imp/Inc of Driving Safely - 1st Off   \n",
       "4538 2020-06-16 00:41:00+00:00    Verify Address or Photographed as Required   \n",
       "120  2020-06-16 00:52:00+00:00                             Criminal Mischief   \n",
       "\n",
       "                            represented_by bail_type bail_status  bail_amount  \\\n",
       "id                                                                              \n",
       "3909  Defender Association of Philadelphia    Posted         ROR            0   \n",
       "4538  Defender Association of Philadelphia       Set    Monetary        50000   \n",
       "120   Defender Association of Philadelphia    Posted         ROR            0   \n",
       "\n",
       "      outstanding_bail_amount  \n",
       "id                             \n",
       "3909                        0  \n",
       "4538                        0  \n",
       "120                         0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indata = pd.read_csv(Path(data_dir) / FILENAME, parse_dates=['filing_date'], index_col='id')\n",
    "\n",
    "indata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Setup\n",
    "\n",
    "A1. Keep = bail_amount, charge, bail_status, filing_date, age, represented_by\n",
    "\n",
    "A2. Create hour of day and day of week from filing_date, then drop originial filing_date\n",
    "\n",
    "A3. Delete rows where bail_status = 'Denied' (we will only worry about ones where there is a set amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A1: Keep only columns that might impact the bail amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['address','docket_number','bail_type','outstanding_bail_amount']\n",
    "\n",
    "indata.drop(columns=drop_list, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A2: Parse Hour of Day and Day of Week, before dropping the date field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datecol = 'filing_date'\n",
    "\n",
    "indata['filed_hour_of_day'] = indata[datecol].dt.hour\n",
    "\n",
    "#The day of the week with Monday=0, Sunday=6\n",
    "indata['filed_day_of_week'] = indata[datecol].dt.dayofweek\n",
    "\n",
    "indata.drop(columns=[datecol], inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A3: Remove rows where bail does not apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>charge</th>\n",
       "      <th>represented_by</th>\n",
       "      <th>bail_status</th>\n",
       "      <th>bail_amount</th>\n",
       "      <th>filed_hour_of_day</th>\n",
       "      <th>filed_day_of_week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4538</th>\n",
       "      <td>44.0</td>\n",
       "      <td>Verify Address or Photographed as Required</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>50000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>32.0</td>\n",
       "      <td>Contempt For Violation of Order or Agreement</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>32.0</td>\n",
       "      <td>Burglary - Overnight Accommodations Person Pre...</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>75000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>32.0</td>\n",
       "      <td>Burglary - Overnight Accommodations Person Pre...</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>75000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>51.0</td>\n",
       "      <td>Simple Assault</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Unsecured</td>\n",
       "      <td>25000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age                                             charge  \\\n",
       "id                                                              \n",
       "4538  44.0         Verify Address or Photographed as Required   \n",
       "291   32.0       Contempt For Violation of Order or Agreement   \n",
       "291   32.0  Burglary - Overnight Accommodations Person Pre...   \n",
       "291   32.0  Burglary - Overnight Accommodations Person Pre...   \n",
       "2396  51.0                                     Simple Assault   \n",
       "\n",
       "                            represented_by bail_status  bail_amount  \\\n",
       "id                                                                    \n",
       "4538  Defender Association of Philadelphia    Monetary        50000   \n",
       "291   Defender Association of Philadelphia    Monetary        50000   \n",
       "291   Defender Association of Philadelphia    Monetary        75000   \n",
       "291   Defender Association of Philadelphia    Monetary        75000   \n",
       "2396  Defender Association of Philadelphia   Unsecured        25000   \n",
       "\n",
       "      filed_hour_of_day  filed_day_of_week  \n",
       "id                                          \n",
       "4538                  0                  1  \n",
       "291                   1                  1  \n",
       "291                   1                  1  \n",
       "291                   1                  1  \n",
       "2396                  1                  1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = indata[indata['bail_amount']>0]\n",
    "\n",
    "clean.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into Train and holdout\n",
    "\n",
    "In case we want to do special encoding that uses target signals, we want to ensure we do this now. But, it means we'll have to remember to apply the transformations to the test dataset as well (more coding, blah)\n",
    "\n",
    "So that I can compare this method with other software and techniques, I'm adding an indicator for the holdout and each of the 5 training folds, so that we can replicate results and compare directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>charge</th>\n",
       "      <th>represented_by</th>\n",
       "      <th>bail_status</th>\n",
       "      <th>bail_amount</th>\n",
       "      <th>filed_hour_of_day</th>\n",
       "      <th>filed_day_of_week</th>\n",
       "      <th>holdout_ind</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Manufacture, Delivery, or Possession With Inte...</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>3700</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>48.0</td>\n",
       "      <td>Simple Assault</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>10000</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4614</th>\n",
       "      <td>30.0</td>\n",
       "      <td>Aggravated Assault - Attempts to cause SBI or ...</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>100000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age                                             charge  \\\n",
       "id                                                              \n",
       "2670  23.0  Manufacture, Delivery, or Possession With Inte...   \n",
       "1142  48.0                                     Simple Assault   \n",
       "4614  30.0  Aggravated Assault - Attempts to cause SBI or ...   \n",
       "\n",
       "                            represented_by bail_status  bail_amount  \\\n",
       "id                                                                    \n",
       "2670  Defender Association of Philadelphia    Monetary         3700   \n",
       "1142  Defender Association of Philadelphia    Monetary        10000   \n",
       "4614  Defender Association of Philadelphia    Monetary       100000   \n",
       "\n",
       "      filed_hour_of_day  filed_day_of_week holdout_ind  \n",
       "id                                                      \n",
       "2670                 13                  2          T1  \n",
       "1142                 20                  4          T1  \n",
       "4614                  4                  2          T1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with pd.option_context('mode.chained_assignment', None):\n",
    "    temptrain, holdoutdata = train_test_split(\n",
    "        clean,\n",
    "        test_size=(1 - HOLDOUT_SIZE),\n",
    "        random_state=1337\n",
    "    )\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "    i = 0\n",
    "    for _ , test_index in kf.split(temptrain,temptrain[TARGET_VARIABLE_NAME]):\n",
    "        i+=1\n",
    "        temp = temptrain.iloc[test_index]\n",
    "        temp[HOLDOUT_INDICATOR_NAME]='T' + str(i)\n",
    "\n",
    "        if i==1:\n",
    "            traindata = temp.copy()\n",
    "        else:\n",
    "            traindata = traindata.append(temp)\n",
    "\n",
    "    holdoutdata[HOLDOUT_INDICATOR_NAME]='H'\n",
    "    clean = pd.concat([traindata,holdoutdata])\n",
    "\n",
    "clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export this data so we can benchmark w/ AutoML tools if we want to\n",
    "clean.to_csv(Path(artifacts_dir) / 'ready_for_external_tests.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "B1. Encode categorical variables (bail_status, hour of day, day of week, represented_by, even charge!) \n",
    "using categorical_encoders library. Choose any method but best is probably Ordinal. Also \n",
    "good to try is just using alphabetical ordering and numbering them 1,2,3.. etc\n",
    "\n",
    "B2. Impute numeric variable (age) with -9999\n",
    "\n",
    "B3. Vectorize and process `charges` as text with NLP techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a hack to be able to put target encoders and regular encoders in the same pipeline\n",
    "clean['fake'] = clean['bail_amount']\n",
    "\n",
    "train = clean[clean['holdout_ind'] != 'H']\n",
    "holdout = clean[clean['holdout_ind'] == 'H']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# variables to modify\n",
    "vars_numeric = ['age']\n",
    "vars_ordinal = ['represented_by','bail_status','filed_hour_of_day','filed_day_of_week']\n",
    "vars_loo = ['charge']\n",
    "vars_txt = ['charge']\n",
    "\n",
    "# basic pipelines\n",
    "pipeline_numeric = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value=-9999))])\n",
    "\n",
    "pipeline_ordinal = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                          ('ord encoding', ce.ordinal.OrdinalEncoder())])\n",
    "\n",
    "pipeline_loo = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                               ('loo encoding', ce.TargetEncoder())])\n",
    "\n",
    "# text vectorizer\n",
    "pipeline_txt = Pipeline(steps=[('vect_counts', CountVectorizer()),\n",
    "                                ('tfidf', TfidfTransformer())\n",
    "                              ])\n",
    "\n",
    "# one unified preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', pipeline_numeric, ['age']),\n",
    "                  ('cat1', pipeline_ordinal, ['bail_status']),\n",
    "                  ('cat2', pipeline_loo, ['charge'])\n",
    "                 ])\n",
    "\n",
    "\n",
    "\n",
    "#                ('txt', pipeline_txt.fit(train[vars_txt]), vars_txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning / Predictive Modeling\n",
    "\n",
    "D1. Random Forest model - use CV to find best parameters\n",
    "\n",
    "D2. Double check RMSE against holdout. Guessing \"average\" for every observation yields RMSE of 1.7e5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### D1: Find the best Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['preprocessor', 'regression']\n",
      "parameters:\n",
      "{'regression__max_depth': [6, None],\n",
      " 'regression__max_features': [0.3],\n",
      " 'regression__min_samples_leaf': [5],\n",
      " 'regression__min_samples_split': [5],\n",
      " 'regression__n_estimators': [100]}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-91cb4aaf4e42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTARGET_VARIABLE_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTARGET_VARIABLE_NAME\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHOLDOUT_INDICATOR_NAME\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done in %0.3fs\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    302\u001b[0m             )\n\u001b[1;32m    303\u001b[0m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0;32m--> 304\u001b[0;31m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    801\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 646\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                     (type_err,\n\u001b[0;32m--> 100\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m    101\u001b[0m             )\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from pprint import pprint\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=500, criterion='mse', max_depth=None\n",
    "                                                       ,min_samples_split=10,min_samples_leaf=5,min_weight_fraction_leaf=0.0\n",
    "                                                       ,max_features=0.3,max_leaf_nodes=1000,min_impurity_decrease=0.0\n",
    "                                                       ,bootstrap=False,oob_score=False,n_jobs=None\n",
    "                                                       ,random_state=1234,verbose=0,warm_start=False,ccp_alpha=0.0,max_samples=None)\n",
    "\n",
    "\n",
    "                           \n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),('regression', rfr)])\n",
    "\n",
    "params = {\"regression__max_depth\": [6, None],\n",
    "              \"regression__max_features\": [0.3],\n",
    "              \"regression__min_samples_split\": [5],\n",
    "              \"regression__min_samples_leaf\": [5],\n",
    "              \"regression__n_estimators\": [100]}\n",
    "\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # multiprocessing requires the fork to happen in a __main__ protected block\n",
    "\n",
    "    gs = GridSearchCV(pipe, param_grid=params, cv = cv, refit=True, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipe.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(params)\n",
    "    \n",
    "    t0 = time()\n",
    "    gs.fit(train.drop(TARGET_VARIABLE_NAME, axis=1), train[TARGET_VARIABLE_NAME], groups=train[HOLDOUT_INDICATOR_NAME])\n",
    "    \n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % gs.best_score_)\n",
    "    pprint(\"Best parameters set:\")\n",
    "    \n",
    "    best_parameters = gs.best_estimator_.get_params()\n",
    "    \n",
    "    for param_name in sorted(params.keys()):\n",
    "        print(\"\\n%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Performance of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = RandomForestRegressor(n_estimators=100, criterion='mse', max_depth=None\n",
    "                                                       ,min_samples_split=5,min_samples_leaf=5,min_weight_fraction_leaf=0.0\n",
    "                                                       ,max_features=0.1,max_leaf_nodes=1000,min_impurity_decrease=0.0\n",
    "                                                       ,bootstrap=False,oob_score=False,n_jobs=None\n",
    "                                                       ,random_state=1234,verbose=0,warm_start=False,ccp_alpha=0.0,max_samples=None)\n",
    "\n",
    "final_pipe = Pipeline(steps=[('preprocessor', preprocessor),('final_model', final_model)])\n",
    "\n",
    "model = final_pipe.fit(train.drop(TARGET_VARIABLE_NAME, axis=1), train[TARGET_VARIABLE_NAME])\n",
    "\n",
    "train_y_pred = model.predict(train.drop(TARGET_VARIABLE_NAME, axis=1))\n",
    "holdout_y_pred = model.predict(holdout.drop(TARGET_VARIABLE_NAME, axis=1))\n",
    "\n",
    "naive_guess = pd.Series(np.mean(train[TARGET_VARIABLE_NAME]))\n",
    "naive_y_pred = naive_guess.repeat(len(holdout_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Error listed as RMSE ******\n",
      "Train (In-Sample): 141188\n",
      "CV: 167191.0\n",
      "Holdout: 156542\n",
      "Naive: 174778\n"
     ]
    }
   ],
   "source": [
    "train_mse = mean_squared_error(train[TARGET_VARIABLE_NAME], train_y_pred)\n",
    "holdout_mse = mean_squared_error(holdout[TARGET_VARIABLE_NAME], holdout_y_pred)\n",
    "naive_mse = mean_squared_error(holdout[TARGET_VARIABLE_NAME], naive_y_pred)\n",
    "\n",
    "print('***** Error listed as RMSE ******')\n",
    "print('Train (In-Sample): ' + str(round(math.sqrt(train_mse))))\n",
    "print('CV: ' + str(-round(gs.best_score_)))\n",
    "print('Holdout: ' + str(round(math.sqrt(holdout_mse))))\n",
    "print('Naive: ' + str(round(math.sqrt(naive_mse))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now we have small data, but at least we have somewhat of a model that is slightly better than average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "E1. Matrix of correlation (mutual information?) to prove these are independent variables\n",
    "\n",
    "E2. Permutation Importance to show the relative importance of each variable in the model (this is a better interpretation than the tree-importance that comes from the model itself)\n",
    "\n",
    "E3. Partial Dependence Plots for each of the variables (except the text)\n",
    "\n",
    "E4. Score original training dataset with model. Filter for observations where predicted value is either top 10% or bottom 10%. Run SHAP to extract #1 reason for each observation in the top/bottom 10%.\n",
    "\n",
    "E5. Look for any cases where age, represented_by is the #1 factor for the bail_amount. These could be interesting cases to highlight\n",
    "\n",
    "E6. Word cloud of the terms - this could take some work I'm not too familiar w/ this\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### E1: Correlation Matrix \n",
    "Can we use Mutual Information ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### E2: Feature Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(pipe, random_state=1).fit(train.drop(TARGET_VARIABLE_NAME, 1), train[TARGET_VARIABLE_NAME])\n",
    "eli5.show_weights(perm, feature_names = train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### E3: Feature Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### E4. Feature Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### E5. Specific Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### E6. Term Frequncy/ Word Cloud?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
