{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Philly Bail Fund\n",
    "## Analysis of factors related to Bail Amounts\n",
    "\n",
    "For more details, see the github repo: https://github.com/CodeForPhilly/pbf-analysis\n",
    "\n",
    "[insert overview of approach here.. img?]\n",
    "\n",
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard Imports - Sorry PEP8 fans, do not look below\n",
    "import pandas as pd, numpy as np, os, re, json, pickle, math, calendar\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "\n",
    "## Specific Imports\n",
    "import hashlib\n",
    "\n",
    "# frameworks\n",
    "from sklearn.model_selection import GroupKFold, KFold\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "# feat engineering\n",
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# modeling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# validation and scoring\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "\n",
    "### Display options for notebooks\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 25)\n",
    "\n",
    "### set path directories\n",
    "curr_dir = Path(os.getcwd())\n",
    "#print('Current Directory is: ', str(curr_dir))\n",
    "data_dir = Path(curr_dir.parents[0] / 'Data/')\n",
    "artifacts_dir = Path(curr_dir / 'artifacts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Common project specific variables\n",
    "FILENAME = '0c_distinct_dockets.csv'  # original data\n",
    "TARGET_VARIABLE_NAME = 'bail_amount'\n",
    "HOLDOUT_INDICATOR_NAME = 'holdout_ind'\n",
    "HOLDOUT_SIZE = 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to reduce memory footprint of the dataframe\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    import numpy as np\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: \n",
    "        print('Mem. usage decreased to {:5.2f} MB ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import\n",
    "\n",
    "Also, check a hash to see if this file has changed since this code was written. If it changes, someone should review this notebook to make sure that the code still works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental - looking to find a way to prevent this notebook from continuing\n",
    "# if by chance the dataset has changed\n",
    "BLOCKSIZE = 65536\n",
    "hasher = hashlib.md5()\n",
    "with open(Path(data_dir) / FILENAME, 'rb') as afile:\n",
    "    buf = afile.read(BLOCKSIZE)\n",
    "    while len(buf) > 0:\n",
    "        hasher.update(buf)\n",
    "        buf = afile.read(BLOCKSIZE)\n",
    "        \n",
    "filehash = hasher.hexdigest()\n",
    "\n",
    "with open(Path(artifacts_dir) / 'data_file_hash.txt', 'rb') as f:\n",
    "    checkhash = pickle.load(f)\n",
    "    \n",
    "if filehash != checkhash:\n",
    "    print(\"!! Warning !! The file is different than when this code was last updated. \\nProceed with caution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bootleg way to update the hash manually, if we know everything is good to go\n",
    "UPDATE_HASH_FLAG = False\n",
    "\n",
    "if UPDATE_HASH_FLAG==True:\n",
    "    with open(Path(artifacts_dir) / 'data_file_hash.txt', 'wb') as f:\n",
    "        pickle.dump(filehash, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>docket_number</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>charge</th>\n",
       "      <th>represented_by</th>\n",
       "      <th>bail_type</th>\n",
       "      <th>bail_status</th>\n",
       "      <th>bail_amount</th>\n",
       "      <th>outstanding_bail_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>27.0</td>\n",
       "      <td>Philadelphia, PA 19141</td>\n",
       "      <td>MC-51-CR-0011746-2020</td>\n",
       "      <td>2020-06-16 00:37:00+00:00</td>\n",
       "      <td>DUI: Gen Imp/Inc of Driving Safely - 1st Off</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Posted</td>\n",
       "      <td>ROR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4538</th>\n",
       "      <td>44.0</td>\n",
       "      <td>Philadelphia, PA 19124</td>\n",
       "      <td>MC-51-CR-0011747-2020</td>\n",
       "      <td>2020-06-16 00:41:00+00:00</td>\n",
       "      <td>Verify Address or Photographed as Required</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Set</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>50000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Philadelphia, PA 19142</td>\n",
       "      <td>MC-51-CR-0011743-2020</td>\n",
       "      <td>2020-06-16 00:52:00+00:00</td>\n",
       "      <td>Criminal Mischief</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Posted</td>\n",
       "      <td>ROR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age                 address          docket_number  \\\n",
       "id                                                          \n",
       "3909  27.0  Philadelphia, PA 19141  MC-51-CR-0011746-2020   \n",
       "4538  44.0  Philadelphia, PA 19124  MC-51-CR-0011747-2020   \n",
       "120   24.0  Philadelphia, PA 19142  MC-51-CR-0011743-2020   \n",
       "\n",
       "                   filing_date                                        charge  \\\n",
       "id                                                                             \n",
       "3909 2020-06-16 00:37:00+00:00  DUI: Gen Imp/Inc of Driving Safely - 1st Off   \n",
       "4538 2020-06-16 00:41:00+00:00    Verify Address or Photographed as Required   \n",
       "120  2020-06-16 00:52:00+00:00                             Criminal Mischief   \n",
       "\n",
       "                            represented_by bail_type bail_status  bail_amount  \\\n",
       "id                                                                              \n",
       "3909  Defender Association of Philadelphia    Posted         ROR            0   \n",
       "4538  Defender Association of Philadelphia       Set    Monetary        50000   \n",
       "120   Defender Association of Philadelphia    Posted         ROR            0   \n",
       "\n",
       "      outstanding_bail_amount  \n",
       "id                             \n",
       "3909                        0  \n",
       "4538                        0  \n",
       "120                         0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data and take a peek at it\n",
    "indata = pd.read_csv(Path(data_dir) / FILENAME, parse_dates=['filing_date'], index_col='id')\n",
    "\n",
    "indata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Setup\n",
    "\n",
    "A1. Keep = bail_amount, charge, bail_status, filing_date, age, represented_by\n",
    "\n",
    "A2. Create hour of day and day of week from filing_date, then drop originial filing_date\n",
    "\n",
    "A3. Delete rows where bail_status = 'Denied' (we will only worry about ones where there is a set amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A1: Keep only columns that might impact the bail amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop things we know aren't useful\n",
    "drop_list = ['address','docket_number','bail_type','outstanding_bail_amount']\n",
    "\n",
    "indata.drop(columns=drop_list, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A2: Parse Hour of Day and Day of Week, before dropping the date field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "datecol = 'filing_date'\n",
    "\n",
    "# hour of day\n",
    "indata['filed_hour_of_day'] = indata[datecol].dt.hour\n",
    "\n",
    "# day of the week with Monday=0, Sunday=6\n",
    "indata['filed_day_of_week'] = indata[datecol].dt.dayofweek.apply(lambda x: calendar.day_abbr[x])\n",
    "\n",
    "indata.drop(columns=[datecol], inplace=True, errors='ignore')\n",
    "\n",
    "indata['charge'] = indata['charge'].str.lower().str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A3: Remove rows where bail does not apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>charge</th>\n",
       "      <th>represented_by</th>\n",
       "      <th>bail_status</th>\n",
       "      <th>bail_amount</th>\n",
       "      <th>filed_hour_of_day</th>\n",
       "      <th>filed_day_of_week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4538</th>\n",
       "      <td>44.0</td>\n",
       "      <td>verify address or photographed as required</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>50000</td>\n",
       "      <td>0</td>\n",
       "      <td>Tue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>32.0</td>\n",
       "      <td>contempt for violation of order or agreement</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>32.0</td>\n",
       "      <td>burglary  overnight accommodations person pres...</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>75000</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>32.0</td>\n",
       "      <td>burglary  overnight accommodations person pres...</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>75000</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>51.0</td>\n",
       "      <td>simple assault</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Unsecured</td>\n",
       "      <td>25000</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age                                             charge  \\\n",
       "id                                                              \n",
       "4538  44.0         verify address or photographed as required   \n",
       "291   32.0       contempt for violation of order or agreement   \n",
       "291   32.0  burglary  overnight accommodations person pres...   \n",
       "291   32.0  burglary  overnight accommodations person pres...   \n",
       "2396  51.0                                     simple assault   \n",
       "\n",
       "                            represented_by bail_status  bail_amount  \\\n",
       "id                                                                    \n",
       "4538  Defender Association of Philadelphia    Monetary        50000   \n",
       "291   Defender Association of Philadelphia    Monetary        50000   \n",
       "291   Defender Association of Philadelphia    Monetary        75000   \n",
       "291   Defender Association of Philadelphia    Monetary        75000   \n",
       "2396  Defender Association of Philadelphia   Unsecured        25000   \n",
       "\n",
       "      filed_hour_of_day filed_day_of_week  \n",
       "id                                         \n",
       "4538                  0               Tue  \n",
       "291                   1               Tue  \n",
       "291                   1               Tue  \n",
       "291                   1               Tue  \n",
       "2396                  1               Tue  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rows where bail amount is more than zero\n",
    "clean = indata[indata['bail_amount']>0]\n",
    "\n",
    "clean.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into Train and holdout\n",
    "\n",
    "In case we want to do special encoding that uses target signals, we want to ensure we do this now. But, it means we'll have to remember to apply the transformations to the test dataset as well (more coding, blah)\n",
    "\n",
    "So that I can compare this method with other software and techniques, I'm adding an indicator for the holdout and each of the 5 training folds, so that we can replicate results and compare directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>charge</th>\n",
       "      <th>represented_by</th>\n",
       "      <th>bail_status</th>\n",
       "      <th>bail_amount</th>\n",
       "      <th>filed_hour_of_day</th>\n",
       "      <th>filed_day_of_week</th>\n",
       "      <th>holdout_ind</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>23.0</td>\n",
       "      <td>manufacture delivery or possession with intent...</td>\n",
       "      <td>None</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>Wed</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4219</th>\n",
       "      <td>41.0</td>\n",
       "      <td>possession of firearm prohibited</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>500000</td>\n",
       "      <td>16</td>\n",
       "      <td>Wed</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3302</th>\n",
       "      <td>61.0</td>\n",
       "      <td>poss instrument of crime wint</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Unsecured</td>\n",
       "      <td>7500</td>\n",
       "      <td>9</td>\n",
       "      <td>Thu</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age                                             charge  \\\n",
       "id                                                              \n",
       "4155  23.0  manufacture delivery or possession with intent...   \n",
       "4219  41.0                   possession of firearm prohibited   \n",
       "3302  61.0                      poss instrument of crime wint   \n",
       "\n",
       "                            represented_by bail_status  bail_amount  \\\n",
       "id                                                                    \n",
       "4155                                  None    Monetary       150000   \n",
       "4219  Defender Association of Philadelphia    Monetary       500000   \n",
       "3302  Defender Association of Philadelphia   Unsecured         7500   \n",
       "\n",
       "      filed_hour_of_day filed_day_of_week holdout_ind  \n",
       "id                                                     \n",
       "4155                  0               Wed          T1  \n",
       "4219                 16               Wed          T1  \n",
       "3302                  9               Thu          T1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a handy little routine that will add a partition indicator including holdout and folds\n",
    "# this is handy for benchmarking in another tool where you want the exact same fold partitions\n",
    "# and cant trust the random seed\n",
    "\n",
    "with pd.option_context('mode.chained_assignment', None):\n",
    "    temptrain, holdoutdata = train_test_split(\n",
    "        clean,\n",
    "        test_size=(1 - HOLDOUT_SIZE),\n",
    "        random_state=321\n",
    "    )\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "    i = 0\n",
    "    for _ , test_index in kf.split(temptrain,temptrain[TARGET_VARIABLE_NAME]):\n",
    "        i+=1\n",
    "        temp = temptrain.iloc[test_index]\n",
    "        temp[HOLDOUT_INDICATOR_NAME]='T' + str(i)\n",
    "\n",
    "        if i==1:\n",
    "            traindata = temp.copy()\n",
    "        else:\n",
    "            traindata = traindata.append(temp)\n",
    "\n",
    "    holdoutdata[HOLDOUT_INDICATOR_NAME]='H'\n",
    "    clean = pd.concat([traindata,holdoutdata])\n",
    "\n",
    "# peek at the data\n",
    "clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export this data so we can benchmark w/ AutoML tools if we want to\n",
    "clean.to_csv(Path(artifacts_dir) / 'ready_for_external_tests.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline including Feature Engineering\n",
    "B1. Encode categorical variables (bail_status, hour of day, day of week, represented_by, even charge!) \n",
    "using categorical_encoders library. Choose any method but best is probably Ordinal. Also \n",
    "good to try is just using alphabetical ordering and numbering them 1,2,3.. etc\n",
    "\n",
    "B2. Impute numeric variable (age) with -9999\n",
    "\n",
    "B3. Vectorize and process `charges` as text with NLP techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split holdout and training data\n",
    "train = clean[clean['holdout_ind'] != 'H']\n",
    "holdout = clean[clean['holdout_ind'] == 'H']\n",
    "\n",
    "# variables that need encoded or treated in special ways\n",
    "vars_numeric = ['age']\n",
    "vars_ordinal = ['represented_by','bail_status','filed_hour_of_day','filed_day_of_week']\n",
    "#vars_tar = ['bail_status']\n",
    "vars_txt = 'charge'\n",
    "\n",
    "# vocab approach for limiting the word vectorizer\n",
    "vocab = ['1st','1st off','agreement','arrest prior','assault','assault by','attempt','attempt burglary','attempt murder','attempt rape','attempt theft','by vehicle','child','compulsion','contempt','contempt for',\n",
    "'crime','crime int','criminal','criminal attempt','criminal mischief','degree','delivery or','driving','driving safely','dui','dui gen','enforcement','enforcement officer','escape','firearm','firearm prohibited',\n",
    "'first','first degree','for','for violation','forcible','forcible compulsion','from','from motor','gen','gen imp','imp','imp inc','inc','inc of','inflict serious','inj','instrument','instrument of','int',\n",
    "'involuntary','involuntary manslaughter','law','law enforcement','manslaughter','mischief','motor vehicle','murder','murder of','of','of crime','of driving','of firearm','of law','of order','of the','off',\n",
    "'officer','officer of','order','order or','other','per','person','person present','poss','poss instrument','possession','possession of','prior','prior to','prohibited','rape','rape forcible','requisition',\n",
    "'safely','simple','simple assault','the','the first','theft','theft from','to requisition','tres','vehicle while','violation','while','while dui']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model only on text features\n",
    "\n",
    "We'll first build a model using the text features, before feeding that prediction into a final model where the txt is now represented as a single column (probability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (Text-Only Model) Grid Search for best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "done in 19.201s\n",
      "\n",
      "Best score: -155431.076\n",
      "Best parameters set:\n",
      "'\\nsubmodel__alpha: 0.0001'\n",
      "'\\nsubmodel__max_iter: 5000'\n",
      "\"\\nsubmodel__penalty: 'l2'\"\n",
      "'\\nsubmodel__tol: 0.001'\n"
     ]
    }
   ],
   "source": [
    "#### text preprocessor\n",
    "# note the .fit() is required for text processing\n",
    "\n",
    "pipeline_txt = Pipeline(steps=[('vect_counts', CountVectorizer(vocabulary=vocab, lowercase=True, ngram_range=(1,3), analyzer='word'))\n",
    "                               ,('vect_tfidf', TfidfTransformer())\n",
    "                              ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('txt', pipeline_txt.fit(train[vars_txt]), vars_txt)\n",
    "                 ])\n",
    "\n",
    "# initiate a model\n",
    "submodel = SGDRegressor()\n",
    "\n",
    "# dimensionality reduction\n",
    "svd = TruncatedSVD()\n",
    "\n",
    "# option A: One combined pipeline                  \n",
    "#textpipe = Pipeline(steps=[('preprocessor', preprocessor),('svd', svd), ('submodel', submodel)])\n",
    "\n",
    "# option B: Do it without svd (by using vocab instead)\n",
    "textpipe_nosvd = Pipeline(steps=[('preprocessor', preprocessor), ('submodel', submodel)])\n",
    "\n",
    "# grid search settings\n",
    "params = {\n",
    "    'submodel__tol': (0.0001, 0.0005, 0.001),\n",
    "    'submodel__alpha': (0.0001, 0.0005, 0.001),\n",
    "    'submodel__penalty': ('l2', 'elasticnet'),\n",
    "    'submodel__max_iter': (1000, 5000)\n",
    "}\n",
    "\n",
    "# initialize a cross fold validation strategy\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "# multiprocessing requires the fork to happen in a __main__ protected block\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # initialize a grid search of the pipeline and parameters \n",
    "    gs = GridSearchCV(textpipe_nosvd, param_grid=params, cv = cv, refit=True, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "    \n",
    "    t0 = time()\n",
    "    \n",
    "    # grid search (go get coffee)\n",
    "    print(\"Performing grid search...\")\n",
    "    xvars = list([vars_txt] + [HOLDOUT_INDICATOR_NAME])\n",
    "    gs.fit(train[xvars], train[TARGET_VARIABLE_NAME], groups=train[HOLDOUT_INDICATOR_NAME])\n",
    "    \n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "    print(\"Best score: %0.3f\" % gs.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    \n",
    "    # print the best settings\n",
    "    best_parameters = gs.best_estimator_.get_params()\n",
    "    \n",
    "    for param_name in sorted(params.keys()):\n",
    "        pprint(\"\\n%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chosen Text Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text vectorizer\n",
    "pipeline_txt = Pipeline(steps=[('vect_counts', CountVectorizer(vocabulary=vocab, lowercase=True, ngram_range=(1,3), analyzer='word'))\n",
    "                              ,('vect_tfidf', TfidfTransformer())\n",
    "                              ])\n",
    "\n",
    "# text preprocessor\n",
    "text_preprocessor = ColumnTransformer(\n",
    "    transformers=[('txt', pipeline_txt.fit(train[vars_txt]), vars_txt)])\n",
    "\n",
    "# text dimensionality reduction\n",
    "#text_svd = TruncatedSVD(n_components=100, n_iter=5)\n",
    "\n",
    "# Final submodel for text features\n",
    "text_submodel = SGDRegressor(max_iter=10000, alpha=0.0, penalty='l2',tol=0.0005)\n",
    "\n",
    "# hardcode the final pipeline\n",
    "text_finalpipe = Pipeline(steps=[('text_preprocessor', text_preprocessor), ('text_submodel',text_submodel)])\n",
    "\n",
    "text_model = text_finalpipe.fit(train[[vars_txt]], train[TARGET_VARIABLE_NAME])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it for later\n",
    "with open(Path(artifacts_dir) / 'text_submodel.mdl', 'wb') as f:\n",
    "    joblib.dump(text_model, f, compress = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intermediate Scoring to replace 'charge' with numeric representation\n",
    "\n",
    "I should be able to figure out how to include this in the pipeline later?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josh.berry/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/josh.berry/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>charge</th>\n",
       "      <th>represented_by</th>\n",
       "      <th>bail_status</th>\n",
       "      <th>bail_amount</th>\n",
       "      <th>filed_hour_of_day</th>\n",
       "      <th>filed_day_of_week</th>\n",
       "      <th>holdout_ind</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>23.0</td>\n",
       "      <td>81500.400170</td>\n",
       "      <td>None</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>Wed</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4219</th>\n",
       "      <td>41.0</td>\n",
       "      <td>245202.990568</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>500000</td>\n",
       "      <td>16</td>\n",
       "      <td>Wed</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3302</th>\n",
       "      <td>61.0</td>\n",
       "      <td>25730.664370</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Unsecured</td>\n",
       "      <td>7500</td>\n",
       "      <td>9</td>\n",
       "      <td>Thu</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         charge                        represented_by bail_status  \\\n",
       "id                                                                            \n",
       "4155  23.0   81500.400170                                  None    Monetary   \n",
       "4219  41.0  245202.990568  Defender Association of Philadelphia    Monetary   \n",
       "3302  61.0   25730.664370  Defender Association of Philadelphia   Unsecured   \n",
       "\n",
       "      bail_amount  filed_hour_of_day filed_day_of_week holdout_ind  \n",
       "id                                                                  \n",
       "4155       150000                  0               Wed          T1  \n",
       "4219       500000                 16               Wed          T1  \n",
       "3302         7500                  9               Thu          T1  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this entire block could be written better\n",
    "train['charge'] = text_model.predict(train[[vars_txt]])\n",
    "holdout['charge'] = text_model.predict(holdout[[vars_txt]])\n",
    "\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (Main Model) Grid Search for best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "done in 32.733s\n",
      "\n",
      "Best score: -141227.811\n",
      "Best parameters set:\n",
      "'\\nregression__max_depth: None'\n",
      "'\\nregression__max_features: 0.6'\n",
      "'\\nregression__min_samples_leaf: 2'\n",
      "'\\nregression__min_samples_split: 10'\n",
      "'\\nregression__n_estimators: 500'\n"
     ]
    }
   ],
   "source": [
    "#### Basic Pipelines\n",
    "# impute missing for numeric columns\n",
    "pipeline_numeric = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value=-9999))])\n",
    "\n",
    "# ordinal encoding\n",
    "pipeline_ordinal = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                          ('ord_encoding', ce.ordinal.OrdinalEncoder())])\n",
    "# target encoding\n",
    "#pipeline_tar = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),('tar_encoding', ce.SumEncoder())])\n",
    "\n",
    "# TODO: fit text into a submodel as part of pipeline\n",
    "\n",
    "#### one unified preprocessor\n",
    "# note the .fit() is required for text processing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', pipeline_numeric, vars_numeric),\n",
    "                  ('cat1', pipeline_ordinal, vars_ordinal)\n",
    "                  #('cat2', pipeline_tar, vars_tar)\n",
    "                 ], remainder='passthrough')\n",
    "\n",
    "# initiate a model\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "# name the final pipeline connected to the model                    \n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor), ('regression', rfr)])\n",
    "\n",
    "# parameter options for grid search\n",
    "params = {\"regression__max_depth\": [6, None],\n",
    "              \"regression__max_features\": [0.6, 0.8],\n",
    "              \"regression__min_samples_split\": [10, 20],\n",
    "              \"regression__min_samples_leaf\": [2, 5],\n",
    "              \"regression__n_estimators\": [200,500]}\n",
    "\n",
    "# initialize a cross fold validation strategy\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "# multiprocessing requires the fork to happen in a __main__ protected block\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # initialize a grid search of the pipeline and parameters \n",
    "    gs = GridSearchCV(pipe, param_grid=params, cv = cv, refit=True, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "    t0 = time()\n",
    "    \n",
    "    # grid search (go get coffee)\n",
    "    print('Performing grid search...')\n",
    "    \n",
    "    X = train.drop([TARGET_VARIABLE_NAME, HOLDOUT_INDICATOR_NAME], axis=1)\n",
    "    y = train[TARGET_VARIABLE_NAME]\n",
    "    \n",
    "    gs.fit(X, y, groups=train[HOLDOUT_INDICATOR_NAME])\n",
    "    \n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % gs.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    \n",
    "    # print the best settings\n",
    "    best_parameters = gs.best_estimator_.get_params()\n",
    "    \n",
    "    for param_name in sorted(params.keys()):\n",
    "        pprint(\"\\n%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### D1: Find the best Random Forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Performance of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Basic Pipelines\n",
    "# impute missing for numeric columns\n",
    "pipeline_numeric = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value=-9999))])\n",
    "\n",
    "# ordinal encoding\n",
    "pipeline_ordinal = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                          ('ord_encoding', ce.ordinal.OrdinalEncoder())])\n",
    "\n",
    "# hardcode the model to the best settings\n",
    "best_model_settings = RandomForestRegressor(n_estimators=500\n",
    "                                            ,criterion='mse'\n",
    "                                            ,max_depth=6\n",
    "                                            ,min_samples_split=10\n",
    "                                            ,min_samples_leaf=2\n",
    "                                            ,min_weight_fraction_leaf=0.0\n",
    "                                            ,max_features=0.6\n",
    "                                            ,max_leaf_nodes=1000\n",
    "                                            ,min_impurity_decrease=0.0\n",
    "                                            ,bootstrap=False\n",
    "                                            ,oob_score=False\n",
    "                                            ,n_jobs=None\n",
    "                                            ,random_state=1234\n",
    "                                            ,verbose=0\n",
    "                                            ,warm_start=False\n",
    "                                            ,ccp_alpha=0.0\n",
    "                                            ,max_samples=None)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', pipeline_numeric, vars_numeric),\n",
    "                  ('cat1', pipeline_ordinal, vars_ordinal)\n",
    "                 ], remainder='passthrough')\n",
    "\n",
    "# hardcode the final pipeline\n",
    "final_pipe = Pipeline(steps=[('preprocessor', preprocessor),('final_model', best_model_settings)])\n",
    "\n",
    "# export the column names for correct ordering\n",
    "cols = train.drop([TARGET_VARIABLE_NAME, HOLDOUT_INDICATOR_NAME], axis=1).columns\n",
    "\n",
    "with open(Path(artifacts_dir) / 'model_col_order.list', 'wb') as f:\n",
    "    joblib.dump(cols, f, compress=0)\n",
    "    \n",
    "# fit the model on the training data (remember this is in-sample and scores will look overfit)\n",
    "model = final_pipe.fit(train[cols], train[TARGET_VARIABLE_NAME])\n",
    "\n",
    "# predictions\n",
    "train_y_pred = model.predict(train.drop([TARGET_VARIABLE_NAME, HOLDOUT_INDICATOR_NAME], axis=1))\n",
    "holdout_y_pred = model.predict(holdout.drop([TARGET_VARIABLE_NAME, HOLDOUT_INDICATOR_NAME], axis=1))\n",
    "\n",
    "# naive guess whatever the average of the training data was\n",
    "naive_guess = pd.Series(np.mean(((train[TARGET_VARIABLE_NAME]) * len(train)) + (np.mean(holdout[TARGET_VARIABLE_NAME]) * len(holdout))) / (len(train) + len(holdout)))\n",
    "naive_y_pred = naive_guess.repeat(len(holdout_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Error listed as RMSE ******\n",
      "Train (In-Sample): 126307\n",
      "CV: 141228.0\n",
      "Holdout: 143172\n",
      "Naive: 177913\n"
     ]
    }
   ],
   "source": [
    "# calc the RMSE\n",
    "train_mse = mean_squared_error(train[TARGET_VARIABLE_NAME], train_y_pred)\n",
    "holdout_mse = mean_squared_error(holdout[TARGET_VARIABLE_NAME], holdout_y_pred)\n",
    "naive_mse = mean_squared_error(holdout[TARGET_VARIABLE_NAME], naive_y_pred)\n",
    "\n",
    "print('***** Error listed as RMSE ******')\n",
    "print('Train (In-Sample): ' + str(round(math.sqrt(train_mse))))\n",
    "try:\n",
    "    print('CV: ' + str(-round(gs.best_score_)))\n",
    "except:\n",
    "    pass\n",
    "print('Holdout: ' + str(round(math.sqrt(holdout_mse))))\n",
    "print('Naive: ' + str(round(math.sqrt(naive_mse))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it for later\n",
    "with open(Path(artifacts_dir) / 'model.mdl', 'wb') as f:\n",
    "    joblib.dump(model, f, compress=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now we have small data, but at least we have somewhat of a model that is slightly better than average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
