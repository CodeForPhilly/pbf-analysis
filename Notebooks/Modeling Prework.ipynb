{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Philly Bail Fund\n",
    "## Analysis of factors related to Bail Amounts\n",
    "\n",
    "For more details, see the github repo: https://github.com/CodeForPhilly/pbf-analysis\n",
    "\n",
    "[insert overview of approach here.. img?]\n",
    "\n",
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard Imports - Sorry PEP8 fans, do not look below\n",
    "import pandas as pd, numpy as np, os, re, json, pickle, math, calendar\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "## Specific Imports\n",
    "import hashlib\n",
    "\n",
    "# frameworks\n",
    "from sklearn.model_selection import GroupKFold, KFold\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "# feat engineering\n",
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# modeling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# validation and scoring\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "\n",
    "### Display options for notebooks\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 25)\n",
    "\n",
    "### set path directories\n",
    "curr_dir = Path(os.getcwd())\n",
    "#print('Current Directory is: ', str(curr_dir))\n",
    "data_dir = Path(curr_dir.parents[0] / 'Data/')\n",
    "artifacts_dir = Path(curr_dir / 'artifacts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Common project specific variables\n",
    "FILENAME = '0c_distinct_dockets.csv'  # original data\n",
    "TARGET_VARIABLE_NAME = 'bail_amount'\n",
    "HOLDOUT_INDICATOR_NAME = 'holdout_ind'\n",
    "HOLDOUT_SIZE = 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to reduce memory footprint of the dataframe\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    import numpy as np\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: \n",
    "        print('Mem. usage decreased to {:5.2f} MB ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import\n",
    "\n",
    "Also, check a hash to see if this file has changed since this code was written. If it changes, someone should review this notebook to make sure that the code still works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimental - looking to find a way to prevent this notebook from continuing\n",
    "# if by chance the dataset has changed\n",
    "BLOCKSIZE = 65536\n",
    "hasher = hashlib.md5()\n",
    "with open(Path(data_dir) / FILENAME, 'rb') as afile:\n",
    "    buf = afile.read(BLOCKSIZE)\n",
    "    while len(buf) > 0:\n",
    "        hasher.update(buf)\n",
    "        buf = afile.read(BLOCKSIZE)\n",
    "        \n",
    "filehash = hasher.hexdigest()\n",
    "\n",
    "with open(Path(artifacts_dir) / 'data_file_hash.txt', 'rb') as f:\n",
    "    checkhash = pickle.load(f)\n",
    "    \n",
    "if filehash != checkhash:\n",
    "    print(\"!! Warning !! The file is different than when this code was last updated. \\nProceed with caution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bootleg way to update the hash manually, if we know everything is good to go\n",
    "UPDATE_HASH_FLAG = False\n",
    "\n",
    "if UPDATE_HASH_FLAG==True:\n",
    "    with open(Path(artifacts_dir) / 'data_file_hash.txt', 'wb') as f:\n",
    "        pickle.dump(filehash, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>docket_number</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>charge</th>\n",
       "      <th>represented_by</th>\n",
       "      <th>bail_type</th>\n",
       "      <th>bail_status</th>\n",
       "      <th>bail_amount</th>\n",
       "      <th>outstanding_bail_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>27.0</td>\n",
       "      <td>Philadelphia, PA 19141</td>\n",
       "      <td>MC-51-CR-0011746-2020</td>\n",
       "      <td>2020-06-16 00:37:00+00:00</td>\n",
       "      <td>DUI: Gen Imp/Inc of Driving Safely - 1st Off</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Posted</td>\n",
       "      <td>ROR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4538</th>\n",
       "      <td>44.0</td>\n",
       "      <td>Philadelphia, PA 19124</td>\n",
       "      <td>MC-51-CR-0011747-2020</td>\n",
       "      <td>2020-06-16 00:41:00+00:00</td>\n",
       "      <td>Verify Address or Photographed as Required</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Set</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>50000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Philadelphia, PA 19142</td>\n",
       "      <td>MC-51-CR-0011743-2020</td>\n",
       "      <td>2020-06-16 00:52:00+00:00</td>\n",
       "      <td>Criminal Mischief</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Posted</td>\n",
       "      <td>ROR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age                 address          docket_number  \\\n",
       "id                                                          \n",
       "3909  27.0  Philadelphia, PA 19141  MC-51-CR-0011746-2020   \n",
       "4538  44.0  Philadelphia, PA 19124  MC-51-CR-0011747-2020   \n",
       "120   24.0  Philadelphia, PA 19142  MC-51-CR-0011743-2020   \n",
       "\n",
       "                   filing_date                                        charge  \\\n",
       "id                                                                             \n",
       "3909 2020-06-16 00:37:00+00:00  DUI: Gen Imp/Inc of Driving Safely - 1st Off   \n",
       "4538 2020-06-16 00:41:00+00:00    Verify Address or Photographed as Required   \n",
       "120  2020-06-16 00:52:00+00:00                             Criminal Mischief   \n",
       "\n",
       "                            represented_by bail_type bail_status  bail_amount  \\\n",
       "id                                                                              \n",
       "3909  Defender Association of Philadelphia    Posted         ROR            0   \n",
       "4538  Defender Association of Philadelphia       Set    Monetary        50000   \n",
       "120   Defender Association of Philadelphia    Posted         ROR            0   \n",
       "\n",
       "      outstanding_bail_amount  \n",
       "id                             \n",
       "3909                        0  \n",
       "4538                        0  \n",
       "120                         0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data and take a peek at it\n",
    "indata = pd.read_csv(Path(data_dir) / FILENAME, parse_dates=['filing_date'], index_col='id')\n",
    "\n",
    "indata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Setup\n",
    "\n",
    "A1. Keep = bail_amount, charge, bail_status, filing_date, age, represented_by\n",
    "\n",
    "A2. Create hour of day and day of week from filing_date, then drop originial filing_date\n",
    "\n",
    "A3. Delete rows where bail_status = 'Denied' (we will only worry about ones where there is a set amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A1: Keep only columns that might impact the bail amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop things we know aren't useful\n",
    "drop_list = ['address','docket_number','bail_type','outstanding_bail_amount']\n",
    "\n",
    "indata.drop(columns=drop_list, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A2: Parse Hour of Day and Day of Week, before dropping the date field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datecol = 'filing_date'\n",
    "\n",
    "# hour of day\n",
    "indata['filed_hour_of_day'] = indata[datecol].dt.hour\n",
    "\n",
    "# day of the week with Monday=0, Sunday=6\n",
    "indata['filed_day_of_week'] = indata[datecol].dt.dayofweek.apply(lambda x: calendar.day_abbr[x])\n",
    "\n",
    "indata.drop(columns=[datecol], inplace=True, errors='ignore')\n",
    "\n",
    "indata['charge'] = indata['charge'].str.lower().str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A3: Remove rows where bail does not apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>charge</th>\n",
       "      <th>represented_by</th>\n",
       "      <th>bail_status</th>\n",
       "      <th>bail_amount</th>\n",
       "      <th>filed_hour_of_day</th>\n",
       "      <th>filed_day_of_week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4538</th>\n",
       "      <td>44.0</td>\n",
       "      <td>verify address or photographed as required</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>50000</td>\n",
       "      <td>0</td>\n",
       "      <td>Tue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>32.0</td>\n",
       "      <td>contempt for violation of order or agreement</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>32.0</td>\n",
       "      <td>burglary  overnight accommodations person pres...</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>75000</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>32.0</td>\n",
       "      <td>burglary  overnight accommodations person pres...</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Monetary</td>\n",
       "      <td>75000</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>51.0</td>\n",
       "      <td>simple assault</td>\n",
       "      <td>Defender Association of Philadelphia</td>\n",
       "      <td>Unsecured</td>\n",
       "      <td>25000</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age                                             charge  \\\n",
       "id                                                              \n",
       "4538  44.0         verify address or photographed as required   \n",
       "291   32.0       contempt for violation of order or agreement   \n",
       "291   32.0  burglary  overnight accommodations person pres...   \n",
       "291   32.0  burglary  overnight accommodations person pres...   \n",
       "2396  51.0                                     simple assault   \n",
       "\n",
       "                            represented_by bail_status  bail_amount  \\\n",
       "id                                                                    \n",
       "4538  Defender Association of Philadelphia    Monetary        50000   \n",
       "291   Defender Association of Philadelphia    Monetary        50000   \n",
       "291   Defender Association of Philadelphia    Monetary        75000   \n",
       "291   Defender Association of Philadelphia    Monetary        75000   \n",
       "2396  Defender Association of Philadelphia   Unsecured        25000   \n",
       "\n",
       "      filed_hour_of_day filed_day_of_week  \n",
       "id                                         \n",
       "4538                  0               Tue  \n",
       "291                   1               Tue  \n",
       "291                   1               Tue  \n",
       "291                   1               Tue  \n",
       "2396                  1               Tue  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rows where bail amount is more than zero\n",
    "clean = indata[indata['bail_amount']>0]\n",
    "\n",
    "clean.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into Train and holdout\n",
    "\n",
    "In case we want to do special encoding that uses target signals, we want to ensure we do this now. But, it means we'll have to remember to apply the transformations to the test dataset as well (more coding, blah)\n",
    "\n",
    "So that I can compare this method with other software and techniques, I'm adding an indicator for the holdout and each of the 5 training folds, so that we can replicate results and compare directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEUCAYAAAAr20GQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de1wU5f4H8M/CAl6wDAMtvJWZN1TUk9fUFBHlkh7y5V08WqTk5WT9QEKOmpmgeDmpWdYxb4kdXimSxzt6xDySpqSxhpckU9EUXLwAcll2fn/Abi4IO4s7zO74eb9evvTZmZ39Pu7sfOd5ZuZ5VIIgCCAioieeg9wBEBGRbWBCICIiAEwIRERUjgmBiIgAMCEQEVE5JgQiIgKggISQl5eHwMBAXLt2rdr1MjMzMWHCBLz++ut48803cffu3VqKkIjIPth1Qjhz5gzGjBmDy5cvV7ueIAgICwtDaGgovvvuO7Rr1w5ffPFF7QRJRGQn1HIH8DgSEhIwb948REREGF/bsWMHNm7cCL1ejw4dOmDevHm4ePEi6tWrh379+gEApk6dinv37skVNhGRTVIp4UnlgQMHYtOmTXjw4AHmzZuH9evXw8XFBcuWLUPdunXRsmVLJCYmwt3dHRkZGXjxxRfxj3/8Aw0bNpQ7dCIim2HXXUYVHT9+HL///jtGjhyJYcOG4eDBg8jMzIROp8OJEycwZswYJCYmolmzZoiNjZU7XCIim2LXXUYVlZaWYujQoYiOjgYA5Ofno7S0FGfPnkWLFi3QsWNHAEBgYCBmzpwpZ6hERDZHUS2EHj164MCBA7h9+zYEQcD8+fOxceNGdOnSBVqtFufOnQMAHDp0CB06dJA5WiIi26KoFkLbtm0xffp0TJw4EXq9Hu3atcPbb78NFxcXfPrpp4iOjsaDBw/QpEkTLFmyRO5wiYhsiiIuKhMR0eNTVJcRERHVnF12Gen1euTn58PJyQkqlUrucIiI7IIgCCgpKUH9+vXh4FC5PWCXCSE/Px8XLlyQOwwiIrv08ssvo0GDBpVet8uE4OTkBKCsUs7OzjJHQ0RkH4qLi3HhwgXjMbQiu0wIhm4iZ2dnuLi4yBwNEZF9qaqrnReViYgIABMCERGVY0IgIiIAEieETz75BP7+/ggICMD69esrLc/IyEBwcDD8/PwwZ84c6HQ6KcOpMa1Wi4iICGi1WrlDISKSjGQJ4cSJE/jhhx/w3XffYdu2bdi8eTMyMzNN1gkPD8fcuXOxb98+CIKAhIQEqcJ5LPHx8Th79iy2bt0qdyhERJKRLCF0794dmzZtglqtxu3bt1FaWop69eoZl2dlZaGwsBDe3t4AgODgYOzdu1eqcGpMq9UiOTkZgiDgwIEDbCUQkWJJ2mXk5OSElStXIiAgAL169ULjxo2Ny27dugV3d3dj2d3dHTdv3pQynBqJj4+HXq8HUPaENFsJRKRUkj+HMHPmTISGhmLq1KlISEjAqFGjAJQdXB++F1YQBIuHodBoNFaN9VEOHjxovLah0+mQnJyMnj17Sv65RES1TbKEcOnSJRQXF6Ndu3aoW7cuBg8ejPPnzxuXN2nSBNnZ2cZyTk4OPDw8LPoMLy8vyR9M8/Hxwf79+6HT6aBWqzFo0CB069ZN0s8kIpJCUVFRtSfSknUZXbt2DdHR0SguLkZxcTEOHjxociD19PSEi4sLTp06BQBISkpCv379pAqnxsaOHWscBMrBwQFjxoyROSIiImlIlhD69++P1157DcOHD8cbb7yBLl26ICAgAKGhoUhPTwcALF26FDExMRgyZAgKCgoQEhIiVTg15ubmhkGDBkGlUsHX1xdubm5yh0REJAm7nCDH0OypjS4joOxOo9jYWERGRjIhEJHdMnfstMvB7Wqbm5sbp9wkIsXj0BVERASACYGIiMoxIRAREQAmBCIiKseEQEREAJgQiIioHBMCEREBYEIgIqJyTAhERASACYGIiMoxIRAREQAmBCIiKseEQEREAJgQiIioHBMCEREBYEIgIqJyTAhERASACYGIiMoxIRAREQAmBCIiKseEQEREAJgQiIioHBMCEREBANRSbnz16tXYs2cPAKB///6IiIiotHzbtm146qmnAAAjR47EuHHjpAyJiIiqIFlCOHbsGI4ePYrExESoVCq89dZbOHDgAHx9fY3raDQaLF++HF26dJEqDCIiEkmyhODu7o7IyEg4OzsDAFq1aoXr16+brKPRaLB27VpkZWXhlVdewezZs+Hi4iJVSEREVA3JriG0bt0a3t7eAIDLly9jz5496N+/v3F5fn4+2rVrh/DwcCQmJuLevXtYs2aNVOEQEZEZKkEQBCk/4OLFi5gyZQpmzJiBv/71r1Wu98svvyAqKgo7duwwu82ioiJoNBprhklE9MTw8vJ6ZG+MpBeVT506hZkzZyIqKgoBAQEmy65fv45jx45hxIgRAABBEKBWWxZOVZUiIqLKzJ1MS9ZldOPGDUybNg1Lly6tlAwAoE6dOoiLi8PVq1chCAK2bNlicsGZiIhql2QthHXr1qGoqAixsbHG10aPHo1Dhw5h5syZ6NixIxYsWICwsDCUlJSga9eumDRpklThEBGRGZJfQ5CCodnDLiMiIvHMHTv5pDIREQFgQiAionJMCEREBIAJgYiIyjEhEBERACYEIiIqx4RAREQAmBCIiKgcEwIREQFgQiAionJMCEREBIAJgYiIyjEhEBERACYEIiIqx4RAREQAmBCIiKgcEwIREQFgQiAionJMCEREBIAJgYiIyjEhEBERACYEIiIqx4RAREQAmBCIiKicpAlh9erVCAgIQEBAAJYsWVJpeUZGBoKDg+Hn54c5c+ZAp9NJGU6NpaSkwN/fH99//73coUhCq9UiIiICWq1W7lAkoeT6cd+0b7ZWP8kSwrFjx3D06FEkJiZix44dOHv2LA4cOGCyTnh4OObOnYt9+/ZBEAQkJCRIFc5jWbZsGQAgLi5O5kikER8fj7Nnz2Lr1q1yhyIJJdeP+6Z9s7X6SZYQ3N3dERkZCWdnZzg5OaFVq1a4fv26cXlWVhYKCwvh7e0NAAgODsbevXulCqfGUlJSjC0XnU6nuDMxrVaL5ORkCIKAAwcO2MyZirUouX7cN+2bLdZPsoTQunVr48H+8uXL2LNnD/r3729cfuvWLbi7uxvL7u7uuHnzplTh1JjhDMxAaWdi8fHx0Ov1AAC9Xm8zZyrWouT6cd+0b7ZYP7XUH3Dx4kVMmTIFERERaNmypfF1vV4PlUplLAuCYFIWQ6PRWCvMKlW8rqHT6XDq1CnJP7e2HDx40OQsMzk5GT179pQ5KutRcv24b9o3W6yfpAnh1KlTmDlzJqKiohAQEGCyrEmTJsjOzjaWc3Jy4OHhYdH2vby84OLiYpVYq6JWq01+eGq1Gt26dZP0M2uTj48P9u/fD51OB7VajUGDBrF+doL7pn2To35FRUXVnkiL7jJ66623Kr02cuTIKte/ceMGpk2bhqVLl1ZKBgDg6ekJFxcX4xlNUlIS+vXrJzacWvP++++blMPDw2WKRBpjx46Fg0PZbuDg4IAxY8bIHJF1Kbl+3Dftmy3Wz2xCmDlzJoKCgnDy5EkEBQUZ/wwdOhRFRUVVvm/dunUoKipCbGwshg0bhmHDhmHr1q0IDQ1Feno6AGDp0qWIiYnBkCFDUFBQgJCQEOvVzEr69+8PtbqsIaVWq9G3b1+ZI7IuNzc3DBo0CCqVCr6+vnBzc5M7JKtScv24b9o3m6yfYMbVq1eFH374QfD19RWOHz9u/HPy5Enhzp075t4uicLCQuHkyZNCYWFhrXze4cOHhaFDhwpHjhyplc+rbbdv3xbCw8OF27dvyx2KJJRcP+6b9q2262fu2KkSBEEQkzj0er2xeSM3Qz9YbVxDICJSCnPHTtEXlQ8dOoRFixbh7t27EATBeFdQWlqaVQMmIiJ5iE4IcXFxiIyMRPv27S2+PZSIiGyf6ITw1FNPYfDgwVLGQkREMhJ9UaBz585ISUmRMhYiIpKR6BZCSkoKvv76azg5OcHJyYnXEIiIFEZ0QtiwYYOEYRARkdxEJ4Q7d+488nVPT0+rBUNERPIRnRBmzJhh/HdJSQmys7Ph5eWFb7/9VpLAiIiodln0HMLDjh8/jp07d1o9ICIikkeNHz3u0aMHzp49a81YiIhIRqJbCA8f/AVBgEajQWFhoSRBERFR7avRNQSVSgU3NzfMnz9fipiIiEgGNb6GQEREyiI6IRQUFGDJkiU4cuQIdDod+vTpgzlz5sDV1VXK+IiIqJaIvqgcExOD4uJifPrpp1izZg1UKhU++ugjKWMjIqJaJLqFcObMGXz33XfG8sKFCx85NSYREdkn0S2E0tJS6PV6Y1mv18PR0VGSoIiIqPaJbiH06tUL7777rnEi6K1bt6JHjx6SBUZERLVLdEKIjIzEmjVrsHz5cpSWlqJv37545513pIyNiIhqkeg5lW0J51QmIrKc1eZU3r17N1auXIm7d++avJ6amvr4URIRkewsmlM5OjoazZs3lzIeIiKSieiE4OnpCR8fHyljISIiGYlOCMOHD8fixYvRr18/qNV/vu2VV16p8j15eXkYPXo0Pv/8czRt2tRk2erVq7Ft2zY89dRTAICRI0di3LhxlsZPRERWIjohHD9+HEeOHMHRo0dNXq9qToQzZ84gOjoaly9ffuRyjUaD5cuXo0uXLuKjJSIiyYhOCL/88guOHDki+q6ehIQEzJs3DxEREY9crtFosHbtWmRlZeGVV17B7NmzeccQEZGMRD+p/Oyzz0Kn04ne8Mcff4y//OUvj1yWn5+Pdu3aITw8HImJibh37x7WrFkjettERGR9olsIjRs3xrBhw9C7d284OzsbX4+Ojrb4Q+vXr48vv/zSWJ48eTKioqIwa9Ysi7aj0Wgs/mwiIno00QmhefPmVrvl9Pr16zh27BhGjBgBoGwGtocvVIvFB9OIiMQzPJhWFdFH4enTp1d6raCgoEZB1alTB3FxcejRoweaNm2KLVu2wNfXt0bbIiIi6xCdEJKTk7Fy5UoUFBRAEATo9XrcuXMHP/30k+gPCw0NxcyZM9GxY0csWLAAYWFhKCkpQdeuXTFp0qQaVYCIiKxD9FhGgwcPxrvvvoutW7ciNDQUycnJqF+/PmbPni11jJVwLCMiIsuZO3aKvsuobt268Pf3h7e3N1xcXDB//nwcPnzYmrESEZGMRCcEFxcXFBcXo3nz5sjIyICDgwNUKpWUsRERUS0SfQ1h4MCBePvtt7F48WKMGjUKp06dwjPPPCNlbEREVItEJ4SpU6fi9ddfR+PGjbFmzRr8+OOPCAwMBACcOHEC3bt3lyxIIiKSnuguIwB4/vnnAQDt27fHxIkT0ahRIwBATEyM9SMjIqJaZVFCqIodTrpGREQVWCUh8OIyEZH9s0pCICIi+8eEQEREAHgNgYiIylklIfTo0cMamyEiIhmZfQ5h6tSp1S7//PPP8cEHH1gtICIikofZhODn51cbcRARkczMJgRfX1+4urrizp07tREPERHJxGxCmDBhAhITE9GzZ0+oVCoIgmDyd0ZGRm3ESUREEjObEBITEwEA586dkzwYIiKSj+jB7YqLi5GSkoL8/HwAQGlpKa5cuYJZs2ZJFhwREdUe0Qlh1qxZuHr1KrKzs9G+fXucOXOGI5wSESmI6OcQMjIysH37dvj4+CAqKgpbt27F3bt3pYyNiIhqkeiE4OHhAbVajZYtW+LChQto3bo17t+/L2VsRERUi0QnhHr16mHnzp1o27Yt9uzZg/Pnz6OgoEDK2IiIqBaJTghz587FuXPn4O3tDZVKhQkTJuDNN9+UMjYiIqpFoi8qA8CPP/6I9evXQ6VSoVu3bnjttdckCouIiGqbRS2EESNG4MyZMzh9+jR8fX0RHR0tZWxERFSLRCeEe/fuYeTIkXBycoKTkxMmTJiAnJycat+Tl5eHwMBAXLt2rdKyjIwMBAcHw8/PD3PmzIFOp7M8+lqSkpICf39/fP/993KHIokNGzbA398fmzZtkjsUSSi5ftw37VtYWBj8/f0xbdo0uUMBYEFCaN68Oc6cOWMsnzt3Ds2bN69y/TNnzmDMmDG4fPnyI5eHh4dj7ty52LdvHwRBQEJCgvioa9myZcsAAHFxcTJHIg3D//0333wjcyTSUHL9uG/at99//x0A8Ntvv8kcSRmzCSEoKAhBQUHQaDQYO3YsgoODMWLECIwYMQJXrlyp8n0JCQmYN28ePDw8Ki3LyspCYWEhvL29AQDBwcHYu3fvY1RDOikpKcbWi06nU9yZ2IYNG0zKSjsTU3L9uG/at7CwMJOyLbQSzF5U/sc//lGjDX/88cdVLrt16xbc3d2NZXd3d9y8ebNGnyM1wxmYQVxcHPr27StTNNZXsWX2zTffICQkRKZorE/J9eO+ad8MrQMDW2glmE0IUgxPodfroVKpjGXDyKmW0mg01gzrkSpe29DpdDh16pTknysn1s8+cN9UHrnrZ9Ftp9bSpEkTZGdnG8s5OTmP7Foyx8vLCy4uLtYMrRK1Wm3yw1Or1ejWrZuknyk31s8+cN9UHqnrV1RUVO2JtFXmVLaUp6cnXFxcjNkwKSkJ/fr1kyMUs95//32Tcnh4uEyRSGPkyJEm5dGjR8sUiTSUXD/um/atRYsWJuUXXnhBpkj+VKsJITQ0FOnp6QCApUuXIiYmBkOGDEFBQYHN9g32798fanVZQ0qtViuqjxYA/va3v5mUbfV7qCkl14/7pn377LPPTMqffvqpTJH8SfKEcOjQITRt2hQA8OWXX6Jjx44AgLZt2+Lbb7/F3r17sWzZMjg7O0sdSo0ZzsSUdgZmYDgTU9oZmIGS68d9074ZWgm20DoAAJUgCILcQVjK0A9WG9cQiIiUwtyxU5ZrCEREZHuYEIiICAATAhERlWNCEEGr1SIiIgJarVbuUIiIJMOEIEJ8fDzOnj2LrVu3yh0KEZFkmBDM0Gq1SE5OhiAIOHDgAFsJRKRYTAhmxMfHo7S0FABQWlqqyFZCWloaAgMDcfr0ablDkYSS66fkugHApUuXMGLECGRmZsodiiRsrTuaCcGMw4cPmySE//73vzJHZH2xsbHQ6/VYtGiR3KFIQsn1U3LdgLIRXAsKChQ734OtdUczIZjh5eVlUjY8aa0UaWlpyMvLA1A2w53SzjSVXD8l1w0oax0Y5lz5/fffFddKsMXuaCYEMyqODGgYi0kpYmNjTcpKO9NUcv2UXDeg8ixwSmsl2GJ3NBOCGQUFBdWW7Z3hDLOqsr1Tcv2UXDcAlWZkrDihjL2zxe5oJgQzXF1dqy3bO9bPfim5bgAqzdlecbhoe9ezZ0+Tcq9evWSK5E9MCGZERkaalKOiomSKRBqsn/1Sct2AyiO4Km1E15rMEik1JgQzunbtajzzcnV1hbe3t8wRWVfXrl1Rr149AEC9evUUWT+lfn9KrhsAtGrVythKaNGiBV588UWZI7Ku1NTUastyYEIQITIyEg4ODoo7AzMw3EmltDuoDJT8/Sm5bkBZq6BevXqKax0AwGuvvWYywdGAAQNkjojzITzxtFotJk+ejOLiYjg7O+Orr76Cm5ub3GERKZ4cvz3Oh0DVio+Ph16vBwDo9XqbuPWNxLO1J11JPDc3NwwaNAgqlQq+vr42cSLGhPCEO3z4MHQ6HQBAp9PZxK1vJJ6tPelKlhk7diw6dOiAMWPGyB0KACaEJ54t9mOSOLb4pCtZxs3NDUuWLLGJ1gHAhPDEGzt2LBwcynYDBwcHmzlTIfPY3UfWxoTwhLPFfkwSh919ZG1MCGRz/ZgkDrv7yNqYEESIiIiAv79/pSdDlWLjxo3QaDTYvHmz3KFIYvz48fD390dISIjcoVjV2LFjTVoISkzoM2bMgL+/P/7+97/LHYokJk6cCH9/f0yaNEnuUABInBB27twJf39/DB48GFu2bKm0fPXq1RgwYACGDRuGYcOGPXIdW2AY8fTnn3+WORJpHDhwAACwb98+mSORhuFia05OjsyRWFfF7j0ldvddunQJAHDx4kWZI5FGdnY2AODmzZsyR1JGsoRw8+ZNrFixAvHx8dixYwf+/e9/49dffzVZR6PRYPny5UhKSkJSUhLGjRsnVTg1FhERYVJWWithxYoVJuVPPvlEpkikMX78eJOykloJYWFhJuVp06bJFIk0ZsyYYVJWWith4sSJJmVbaCVIlhCOHTuGnj17omHDhqhXrx78/Pywd+9ek3U0Gg3Wrl2LoKAgLFiwAEVFRVKFU2MV50NQWivB0DowUForoeKtmEpqJVQcDvq3336TKRJpGFoHBkprJRhaBwa20EpQS7XhW7duwd3d3Vj28PAwOZjm5+ejXbt2CA8PR4sWLRAZGYk1a9Zg1qxZoj+j4sG6tpw6dUqWz60trJ/9UnLdANZPapIlBL1ebzK8qyAIJuX69evjyy+/NJYnT56MqKgoixKCXGMZdevWrdY/szaxfvZLyXUDWL/HZRjLqCqSdRk1adLEpEmUnZ0NDw8PY/n69ev49ttvjWVBEIy30NmSinMqd+rUSaZIpOHr62tS9vPzkykSaVS80Prss8/KFIn1eXp6mpSbNWsmUyTSaNWqlUm5devWMkUijYd7UACgcePGMkXyJ8kSQu/evZGamgqtVosHDx5g//796Nevn3F5nTp1EBcXh6tXr0IQBGzZsqXSwckWLFmyxKRccR5be1exRaa0C3dff/21SXnTpk0yRWJ9nTt3Nikr7WRl1apVJmWl3fCwceNGk/L69etliuRPkiWExo0bY9asWQgJCcHw4cMRGBiITp06ITQ0FOnp6XBzc8OCBQsQFhaGIUOGQBAEm7jK/iiGVoLSfnAGjo6OJn+TfTh8+LBJWYlPKhtaCUprHRg8PGyMLZC0jyYoKAhBQUEmrz183cDPz88uuigqthKUJC0tzWSi79OnTytq5q20tDSTspLq17NnTxw6dMhYtoU5ea2tYitBSS5dumQyFlVmZqbss8LZRlqycWlpaQgMDMTp06flDsXqKnaBLVq0SKZIpKHk+tninLzWlpKSAn9/f3z//fdyh2J1cXFx1ZblwIQgQmxsLPR6vaIOJgZ5eXnVlu2dkutni3PyWtuyZcsA2MbB0tquXLliUq74XIkcmBDMSEtLMx5E8vLyFNdKqF+/frVle1e3bt1qy/bsueeeMyk///zzMkUijZSUFJOxmpTWSnj66aerLcuBCcEMJXc5AECHDh1MyhVvs7V3rq6u1ZbtWcUneSsODWPvDK0DA6W1Eu7evVttWQ5MCGYoucsBqPy0d3p6ukyRSKPi8AAVy2S7DK2DqspkfUwIZij5DBMoG1P/YUobU7958+Ym5RYtWsgUCVmq4kXzJ+EiutyYEMyo2KXSsWNHmSKRRklJiUlZaWdhbdq0MSm3bdtWpkisT+lPKle8N99W7tW3lifqSWWlOH78uElZaXdyKH20UyXXLysry6R89epVmSKRhuH5mKrK9s4WRztlQiAiIgBMCEREVI4JgYiIADAhEBFROdubgKCWHDx4EPv376/Re2fPnl3t8sGDB8PHx6dG2ybzHue7A2z/+5Ny3wTkr5/S2fOx5YlNCGI5Ojqa3N3AIaLJVqhUKgiCYFK2B/Z8wLQmBwcH42inhrLcntiE4OPjI3rH8ff3N/57586dUoVEIlny3QGm39/u3bulCMmqarpv7tq1S6qQZNGxY0eTJ+ft5Rmgmn5///nPf6QKSbQnNiFYwtBKUNrgYU8aJycnuUOwOkMrwZ6mBq3JAbNu3bpYvHixlGHJwtBKsIWH0gAmBFHat28PAIrcIZ8EhjNLJX5/hsEIlVg3QNnfHfDnSAi2Uj8mBIUS20/r5uYGrVZrUlZSPy0RiSf/VQySlYeHR7VlInpysIWgUJb0044fPx5arRYBAQGYNm2axJERka1SCQ/ft2YnioqKoNFo4OXlBRcXF+Pra9euRWZmptU/z7BNKSbAfvHFFzFlyhSrb9cS7733Hq5cuYIvvvgCbm5ussQg1XcH2Mb3Z4/7pmG7Sq2fJb89pdSvqmOngaJaCJmZmUg/ew6OdZ6x6nb1urKetV8uWXc0wtLCXNHrSnnAvHr1KlQqlSQXtsT+6DIzM6E5dxbqhpV30seldygb0vvcH9adUUx3p0j0upmZmTiv0eBZR+v+5JzK72O/nXHOqtsFgJxS8UOhZ2Zm4pdfzqN+XeueUJTqyv6/fv/NuhMb5T/Qml/pIZmZmcg4q4FrXWerxiGUlD3jdDXzglW3m/eguEbvU1RCAADHOs+gwYu+cochyv3MA+ZXKpeZmYmLv2jQxNX6t07W1ZftlPevnLfqdv/IKzG/0kPUDV3wzGtNrRqDlHIPX7No/Wcd1QhuKE8LrCa237HsoFm/rhs6tfY3v6IN+Pmi5c+juNZ1xl9eso9rbCd/vVWj9ykuIShZE1cnvNnFfu43X/dTjtwhEJEFJL3LaOfOnfD398fgwYOxZcuWSsszMjIQHBwMPz8/zJkzR3GzdRER2RPJWgg3b97EihUrsH37djg7O2P06NHo0aMHXnrpJeM64eHhWLhwIby9vREVFYWEhASMHTu2xp+Zm5uL0sJci7pi5FRamIvcXHF9krm5ucjOK7Grs+4beSXQ5Yq7TpKbmwvdnSKLu2HkpLtThFwX8fXL0eks7oaRU45OBwcLvr/8gts16oqRQ37BbeTmij/85ebm4v6D4hp3xdS2+w+KkSvyu3uYZAnh2LFj6NmzJxo2bAgA8PPzw969ezF9+nQAZdP/FRYWwtvbGwAQHByMlStXPlZCAADodeIu1gr6sj9SUDmU/TFHb1mLqLhUwA2R/fKlgoBSiarn6AA4ihhIrbjUshvYBJ1e1IVaQS8AeglvjnNQQeVgvn6CzrL/4BIIyBHRCi6FAIm+OgBl3QKOMF+/Elj2f1yq1yG/4LbZ9fSCHoJEvz2VygEOIn57pRb+9sreI+C+iIu1giBItns6qMQNYlhawwAkSwi3bt0ymUTaw8MDP//8c5XL3d3dLZ5TVKPRmJSbNWsGtVpclfLy8nD//n2LPk+sBg0awNXVVdS6zz33HE6dOmV2Pdig2kUAAAh4SURBVEvqBii7flLWDWD9HmZv9ZOiboDy62cgWULQ6/UmmUwQBJOyueViVLyXtlu3bo8RsW1Tct0A1s/esX72wfAcQlUku6jcpEkTZGf/ee9wdna2ybAIFZfn5ORw2AQiIhlJlhB69+6N1NRUaLVaPHjwAPv370e/fv2Myz09PeHi4mJs0iQlJZksJyKi2iVZQmjcuDFmzZqFkJAQDB8+HIGBgejUqRNCQ0ONk14sXboUMTExGDJkCAoKChASEiJVOEREZIaixjIiIqKqmTt2cvhrIiICwIRARETlmBCIiAiAnQ5uZ7jsUVxcsyFeiYieRIZjZlWXju0yIZSUlA3fcOGCdccQJyJ6EpSUlKBOnTqVXrfLu4z0ej3y8/Ph5ORk8dPNRERPKkEQUFJSgvr168PBofIVA7tMCEREZH28qExERACYEIiIqBwTAhERAWBCICKickwIREQEgAmBiIjKMSEQEREAO31SWUoffvgh0tLSUFJSgitXrqBVq1YAgJCQELzxxhs4f/483nvvPezatUvmSGumqvqNGDECJ0+eRGZmJgBg6tSpCAgIkDNUi1VXtxMnTuDy5ctwdHREREQEevfuLXO0ljO3b+p0OowbNw6jRo1CcHCwzNFarqr6jRs3DrGxsWjWrJlx3e3bt8PR0VGuUB/btWvXEBISgkOHDpm83qZNG5w/f16mqAAI9EhXr14VBgwYYPJaYmKi8Oqrr1Z63R5VrN/y5cuF2NhYQRAEIScnR+jTp4+QnZ0tV3iPpWLdVq1aJcTFxQmCIAi//vqr0KdPH7lCs4pH7ZuCIAj//Oc/he7duwvbtm2TISrrqVi/9PR0YfLkyTJGZH1VfYcvv/yyDNH8iV1GIt2/fx8HDx7E8uXL5Q5FEt27d8eECRMAAI0aNULDhg2Rk5Mjc1TWMX36dLz77rsAys7Mnn76aZkjsr60tDScO3cOAwYMkDsUq0tPT4dWq0VwcDBGjhyJEydOyB2SYrHLSKQGDRpg1apVuHbtmtyhSKJPnz7Gf+/evRvFxcV46aWXZIzIutRqNd58802kpqZiwYIFcodjVXl5eYiJicFnn32GpUuXyh2O1alUKvj4+GDKlCm4ePEiQkNDsXPnTri5uckd2mO5desWhg0bJncYJpgQyMSePXuwaNEi/Otf/4JarazdY926dcjKysLo0aPRpUsXYx+1vfvwww8xZcoUPPvss3KHIonRo0cb/92+fXt06tQJaWlpGDRokIxRPT4PDw8kJSWZvNamTRuZoimjrF88PZbNmzdj3bp1WLdunew7pjWdOHECLVu2hIeHBzw9PdGlSxdcvHhREQkhLy8PqampuHDhAlatWoUbN27ghx9+gFqtxuuvvy53eFaxY8cOdO3aFc2bNwdQNmKnk5OTzFEpE68hEAAgOTkZGzZswNatWxWVDADg8OHD+OKLLwCUNdM1Gg06duwoc1TW4erqiqNHjyIpKQlJSUkYOHAgZs6cqZhkAADnz5/HV199BQDIzMxERkYGunXrJnNUysQWAgEAVq5ciaKiIkydOtX42sKFCxVx4HznnXcwZ84cBAUFwdHREVFRUfD09JQ7LBJp2rRpiIqKQmBgIFQqFRYvXgxXV1e5w1IkzodAREQA2GVERETlmBCIiAgAEwIREZVjQiAiIgBMCEREVI4JgYiIADAhkIIdP34cgYGBFr2nTZs20Gq1lV5ft24dIiMjaxzL/fv3ERISYna9gwcPYuHChRZtOz09HQMHDqxpaERGfDCNqBbcvXsX6enpZtfz8fGBj49PLUREVBkTAilaQUEBZs2ahczMTBQVFWHhwoVo06YNPvzwQ5w7dw4qlQp9+/bFe++9ZzKYX0lJCRYuXIhjx46hUaNGaNSoERo0aAAA+OOPPzB//nxkZWVBEAQMHz4cb731Fq5du4agoCD89NNPAGBS/uCDD1BYWIhhw4ZVO7nL9u3bsW/fPqxduxYTJkyAt7c30tLScOPGDfTq1QsfffQRHBwcEB8fj40bN8LV1RUvv/yy9P+R9ERgQiBF++OPP7BixQp07twZGzZswKpVq9CkSRM0bNgQO3fuRElJCcLCwvDVV1/h7bffNr4vPj4ely9fxq5du6DT6TB+/HhjQvi///s/+Pj4YNKkSbh//z7GjRuH5557Dp07d64yjpiYGAQFBVUa3dKcK1euYPPmzSgoKMDQoUNx4sQJPP3001i9ejWSkpLg7u6OuXPn1uw/h6gCXkMgRWvWrJnxQN22bVtotVocOXIE48ePh0qlgrOzM0aPHo0jR46YvC81NRWBgYFwdnZGvXr1EBQUBKCsxZGWloZx48YBKJsnIzg4uNL7rWXAgAFwcHCAq6srWrRogbt37yI1NRV9+vSBu7s7AGDUqFGSfDY9eZgQSNEeHiZZpVJBEATo9XqoVCrj63q9HjqdrtrtGLp49Ho9Kg7/ZXi/YfsGJSUljx1/nTp1KsUPwORz7HluYbItTAj0xHn11Vfx9ddfQxAEFBcXIyEhAb179zZZp2/fvtixYweKiopQVFSE3bt3Aygbbrpz587YsmULgLK7h3bs2IHevXvjqaeeQklJCX799VcAwK5du4zbU6vVKC0trZRMaqJPnz743//+hz/++AMAkJiY+NjbJAKYEOgJFB0dDa1Wi6CgIAQFBeGFF14wGfYbKJuly8vLC4GBgRg/fjyaNm1qXLZ06VKkpqYiKCgII0aMwODBgxEcHIwGDRogPDwcoaGheOONN+Di4mJ8j7u7Ozp16oSAgADk5uY+Vvxt2rRBeHg4Jk6ciODgYBQVFT3W9ogMOPw1EREB4F1GRLVu7NixyM/Pf+SyLVu2cPIXkg1bCEREBIDXEIiIqBwTAhERAWBCICKickwIREQEgAmBiIjK/T+9iGhxHwuuwwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a handy little routine that will add a partition indicator including holdout and folds\n",
    "# this is handy for benchmarking in another tool where you want the exact same fold partitions\n",
    "# and cant trust the random seed\n",
    "\n",
    "with pd.option_context('mode.chained_assignment', None):\n",
    "    temptrain, holdoutdata = train_test_split(\n",
    "        clean,\n",
    "        test_size=(1 - HOLDOUT_SIZE),\n",
    "        random_state=321\n",
    "    )\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "    i = 0\n",
    "    for _ , test_index in kf.split(temptrain,temptrain[TARGET_VARIABLE_NAME]):\n",
    "        i+=1\n",
    "        temp = temptrain.iloc[test_index]\n",
    "        temp[HOLDOUT_INDICATOR_NAME]='T' + str(i)\n",
    "\n",
    "        if i==1:\n",
    "            traindata = temp.copy()\n",
    "        else:\n",
    "            traindata = traindata.append(temp)\n",
    "\n",
    "    holdoutdata[HOLDOUT_INDICATOR_NAME]='H'\n",
    "    clean = pd.concat([traindata,holdoutdata])\n",
    "\n",
    "# peek at the data\n",
    "clean.head(3)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.boxplot(x=HOLDOUT_INDICATOR_NAME, y=\"bail_amount\", data=clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export this data so we can benchmark w/ AutoML tools if we want to\n",
    "clean.to_csv(Path(artifacts_dir) / 'ready_for_external_tests.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline including Feature Engineering\n",
    "B1. Encode categorical variables (bail_status, hour of day, day of week, represented_by, even charge!) \n",
    "using categorical_encoders library. Choose any method but best is probably Ordinal. Also \n",
    "good to try is just using alphabetical ordering and numbering them 1,2,3.. etc\n",
    "\n",
    "B2. Impute numeric variable (age) with -9999\n",
    "\n",
    "B3. Vectorize and process `charges` as text with NLP techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split holdout and training data\n",
    "train = clean[clean['holdout_ind'] != 'H']\n",
    "holdout = clean[clean['holdout_ind'] == 'H']\n",
    "\n",
    "# variables that need encoded or treated in special ways\n",
    "vars_numeric = ['age']\n",
    "vars_ordinal = ['represented_by','bail_status','filed_hour_of_day','filed_day_of_week']\n",
    "#vars_tar = ['bail_status']\n",
    "vars_txt = 'charge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model only on text features\n",
    "\n",
    "We'll first build a model using the text features, before feeding that prediction into a final model where the txt is now represented as a single column (probability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (Text-Only Model) Grid Search for best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "done in 19.201s\n",
      "\n",
      "Best score: -155431.076\n",
      "Best parameters set:\n",
      "'\\nsubmodel__alpha: 0.0001'\n",
      "'\\nsubmodel__max_iter: 5000'\n",
      "\"\\nsubmodel__penalty: 'l2'\"\n",
      "'\\nsubmodel__tol: 0.001'\n"
     ]
    }
   ],
   "source": [
    "#### text preprocessor\n",
    "# note the .fit() is required for text processing\n",
    "vocab = ['1st','1st off','agreement','arrest prior','assault','assault by','attempt','attempt burglary','attempt murder','attempt rape','attempt theft','by vehicle','child','compulsion','contempt','contempt for',\n",
    "'crime','crime int','criminal','criminal attempt','criminal mischief','degree','delivery or','driving','driving safely','dui','dui gen','enforcement','enforcement officer','escape','firearm','firearm prohibited',\n",
    "'first','first degree','for','for violation','forcible','forcible compulsion','from','from motor','gen','gen imp','imp','imp inc','inc','inc of','inflict serious','inj','instrument','instrument of','int',\n",
    "'involuntary','involuntary manslaughter','law','law enforcement','manslaughter','mischief','motor vehicle','murder','murder of','of','of crime','of driving','of firearm','of law','of order','of the','off',\n",
    "'officer','officer of','order','order or','other','per','person','person present','poss','poss instrument','possession','possession of','prior','prior to','prohibited','rape','rape forcible','requisition',\n",
    "'safely','simple','simple assault','the','the first','theft','theft from','to requisition','tres','vehicle while','violation','while','while dui']\n",
    "\n",
    "pipeline_txt = Pipeline(steps=[('vect_counts', CountVectorizer(vocabulary=vocab, lowercase=True, ngram_range=(1,3), analyzer='word'))\n",
    "                               ,('vect_tfidf', TfidfTransformer())\n",
    "                              ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('txt', pipeline_txt.fit(train[vars_txt]), vars_txt)\n",
    "                 ])\n",
    "\n",
    "# initiate a model\n",
    "submodel = SGDRegressor()\n",
    "\n",
    "# dimensionality reduction\n",
    "svd = TruncatedSVD()\n",
    "\n",
    "# option A: One combined pipeline                  \n",
    "#textpipe = Pipeline(steps=[('preprocessor', preprocessor),('svd', svd), ('submodel', submodel)])\n",
    "\n",
    "# option B: Do it without svd (by using vocab instead)\n",
    "textpipe_nosvd = Pipeline(steps=[('preprocessor', preprocessor), ('submodel', submodel)])\n",
    "\n",
    "# grid search settings\n",
    "params = {\n",
    "    'submodel__tol': (0.0001, 0.0005, 0.001),\n",
    "    'submodel__alpha': (0.0001, 0.0005, 0.001),\n",
    "    'submodel__penalty': ('l2', 'elasticnet'),\n",
    "    'submodel__max_iter': (1000, 5000)\n",
    "}\n",
    "\n",
    "# initialize a cross fold validation strategy\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "# multiprocessing requires the fork to happen in a __main__ protected block\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # initialize a grid search of the pipeline and parameters \n",
    "    gs = GridSearchCV(textpipe_nosvd, param_grid=params, cv = cv, refit=True, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "    \n",
    "    t0 = time()\n",
    "    \n",
    "    # grid search (go get coffee)\n",
    "    print(\"Performing grid search...\")\n",
    "    xvars = list([vars_txt] + [HOLDOUT_INDICATOR_NAME])\n",
    "    gs.fit(train[xvars], train[TARGET_VARIABLE_NAME], groups=train[HOLDOUT_INDICATOR_NAME])\n",
    "    \n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "    print(\"Best score: %0.3f\" % gs.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    \n",
    "    # print the best settings\n",
    "    best_parameters = gs.best_estimator_.get_params()\n",
    "    \n",
    "    for param_name in sorted(params.keys()):\n",
    "        pprint(\"\\n%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chosen Text Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text vectorizer\n",
    "pipeline_txt = Pipeline(steps=[('vect_counts', CountVectorizer(vocabulary=vocab, lowercase=True, ngram_range=(1,3), analyzer='word'))\n",
    "                              ,('vect_tfidf', TfidfTransformer())\n",
    "                              ])\n",
    "\n",
    "# text preprocessor\n",
    "text_preprocessor = ColumnTransformer(\n",
    "    transformers=[('txt', pipeline_txt.fit(train[vars_txt]), vars_txt)])\n",
    "\n",
    "# text dimensionality reduction\n",
    "#text_svd = TruncatedSVD(n_components=100, n_iter=5)\n",
    "\n",
    "# Final submodel for text features\n",
    "text_submodel = SGDRegressor(max_iter=10000, alpha=0.0, penalty='l2',tol=0.0005)\n",
    "\n",
    "# hardcode the final pipeline\n",
    "text_finalpipe = Pipeline(steps=[('text_preprocessor', text_preprocessor), ('text_submodel',text_submodel)])\n",
    "\n",
    "text_model = text_finalpipe.fit(train[[vars_txt]], train[TARGET_VARIABLE_NAME])\n",
    "\n",
    "# save it for later\n",
    "with open(Path(artifacts_dir) / 'text_submodel.mdl', 'wb') as f:\n",
    "    pickle.dump(text_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it for later\n",
    "with open(Path(artifacts_dir) / 'text_submodel.mdl', 'wb') as f:\n",
    "    pickle.dump(text_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intermediate Scoring to replace 'charge' with numeric representation\n",
    "\n",
    "I should be able to figure out how to include this in the pipeline later?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josh.berry/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/josh.berry/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# this entire block could be written better\n",
    "\n",
    "train['temp'] = text_model.predict(train[[vars_txt]])\n",
    "holdout['temp'] = text_model.predict(holdout[[vars_txt]])\n",
    "\n",
    "train = train.drop([vars_txt], axis=1)\n",
    "holdout = holdout.drop([vars_txt], axis=1)\n",
    "\n",
    "train = train.rename(columns={'temp': 'charge'})\n",
    "holdout = holdout.rename(columns={'temp': 'charge'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (Main Model) Grid Search for best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "done in 32.185s\n",
      "\n",
      "Best score: -141105.253\n",
      "Best parameters set:\n",
      "'\\nregression__max_depth: None'\n",
      "'\\nregression__max_features: 0.6'\n",
      "'\\nregression__min_samples_leaf: 5'\n",
      "'\\nregression__min_samples_split: 10'\n",
      "'\\nregression__n_estimators: 500'\n"
     ]
    }
   ],
   "source": [
    "#### Basic Pipelines\n",
    "# impute missing for numeric columns\n",
    "pipeline_numeric = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value=-9999))])\n",
    "\n",
    "# ordinal encoding\n",
    "pipeline_ordinal = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                                          ('ord_encoding', ce.ordinal.OrdinalEncoder())])\n",
    "# target encoding\n",
    "#pipeline_tar = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value='missing')),('tar_encoding', ce.SumEncoder())])\n",
    "\n",
    "# TODO: fit text into a submodel as part of pipeline\n",
    "\n",
    "#### one unified preprocessor\n",
    "# note the .fit() is required for text processing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', pipeline_numeric, vars_numeric),\n",
    "                  ('cat1', pipeline_ordinal, vars_ordinal)\n",
    "                  #('cat2', pipeline_tar, vars_tar)\n",
    "                 ], remainder='passthrough')\n",
    "\n",
    "# initiate a model\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "# name the final pipeline connected to the model                    \n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor), ('regression', rfr)])\n",
    "\n",
    "# parameter options for grid search\n",
    "params = {\"regression__max_depth\": [6, None],\n",
    "              \"regression__max_features\": [0.6, 0.8],\n",
    "              \"regression__min_samples_split\": [10, 20],\n",
    "              \"regression__min_samples_leaf\": [2, 5],\n",
    "              \"regression__n_estimators\": [200,500]}\n",
    "\n",
    "# initialize a cross fold validation strategy\n",
    "cv = GroupKFold(n_splits=5)\n",
    "\n",
    "# multiprocessing requires the fork to happen in a __main__ protected block\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # initialize a grid search of the pipeline and parameters \n",
    "    gs = GridSearchCV(pipe, param_grid=params, cv = cv, refit=True, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "    t0 = time()\n",
    "    \n",
    "    # grid search (go get coffee)\n",
    "    print('Performing grid search...')\n",
    "    \n",
    "    X = train.drop([TARGET_VARIABLE_NAME, HOLDOUT_INDICATOR_NAME], axis=1)\n",
    "    y = train[TARGET_VARIABLE_NAME]\n",
    "    \n",
    "    gs.fit(X, y, groups=train[HOLDOUT_INDICATOR_NAME])\n",
    "    \n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % gs.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    \n",
    "    # print the best settings\n",
    "    best_parameters = gs.best_estimator_.get_params()\n",
    "    \n",
    "    for param_name in sorted(params.keys()):\n",
    "        pprint(\"\\n%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### D1: Find the best Random Forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Performance of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardcode the model to the best settings\n",
    "best_model_settings = RandomForestRegressor(n_estimators=500\n",
    "                                            ,criterion='mse'\n",
    "                                            ,max_depth=6\n",
    "                                            ,min_samples_split=10\n",
    "                                            ,min_samples_leaf=2\n",
    "                                            ,min_weight_fraction_leaf=0.0\n",
    "                                            ,max_features=0.6\n",
    "                                            ,max_leaf_nodes=1000\n",
    "                                            ,min_impurity_decrease=0.0\n",
    "                                            ,bootstrap=False\n",
    "                                            ,oob_score=False\n",
    "                                            ,n_jobs=None\n",
    "                                            ,random_state=1234\n",
    "                                            ,verbose=0\n",
    "                                            ,warm_start=False\n",
    "                                            ,ccp_alpha=0.0\n",
    "                                            ,max_samples=None)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', pipeline_numeric, vars_numeric),\n",
    "                  ('cat1', pipeline_ordinal, vars_ordinal)\n",
    "                 ], remainder='passthrough')\n",
    "\n",
    "# hardcode the final pipeline\n",
    "final_pipe = Pipeline(steps=[('preprocessor', preprocessor),('final_model', best_model_settings)])\n",
    "\n",
    "# fixing a weird ordering problem\n",
    "#train_new = pd.DataFrame(train, columns=train.columns)\n",
    "\n",
    "# fit the model on the training data (remember this is in-sample and scores will look overfit)\n",
    "model = final_pipe.fit(train_new.drop([TARGET_VARIABLE_NAME, HOLDOUT_INDICATOR_NAME], axis=1), y)\n",
    "\n",
    "# predictions\n",
    "train_y_pred = model.predict(train.drop([TARGET_VARIABLE_NAME, HOLDOUT_INDICATOR_NAME], axis=1))\n",
    "holdout_y_pred = model.predict(holdout.drop([TARGET_VARIABLE_NAME, HOLDOUT_INDICATOR_NAME], axis=1))\n",
    "\n",
    "# naive guess whatever the average of the training data was\n",
    "naive_guess = pd.Series(np.mean(((train[TARGET_VARIABLE_NAME]) * len(train)) + (np.mean(holdout[TARGET_VARIABLE_NAME]) * len(holdout))) / (len(train) + len(holdout)))\n",
    "naive_y_pred = naive_guess.repeat(len(holdout_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it for later\n",
    "with open(Path(artifacts_dir) / 'model.mdl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Error listed as RMSE ******\n",
      "Train (In-Sample): 126277\n",
      "CV: 141105.0\n",
      "Holdout: 143622\n",
      "Naive: 177913\n"
     ]
    }
   ],
   "source": [
    "# calc the RMSE\n",
    "train_mse = mean_squared_error(train[TARGET_VARIABLE_NAME], train_y_pred)\n",
    "holdout_mse = mean_squared_error(holdout[TARGET_VARIABLE_NAME], holdout_y_pred)\n",
    "naive_mse = mean_squared_error(holdout[TARGET_VARIABLE_NAME], naive_y_pred)\n",
    "\n",
    "print('***** Error listed as RMSE ******')\n",
    "print('Train (In-Sample): ' + str(round(math.sqrt(train_mse))))\n",
    "print('CV: ' + str(-round(gs.best_score_)))\n",
    "print('Holdout: ' + str(round(math.sqrt(holdout_mse))))\n",
    "print('Naive: ' + str(round(math.sqrt(naive_mse))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now we have small data, but at least we have somewhat of a model that is slightly better than average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "E1. Matrix of correlation (mutual information?) to prove these are independent variables\n",
    "\n",
    "E2. Permutation Importance to show the relative importance of each variable in the model (this is a better interpretation than the tree-importance that comes from the model itself)\n",
    "\n",
    "E3. Partial Dependence Plots for each of the variables (except the text)\n",
    "\n",
    "E4. Score original training dataset with model. Filter for observations where predicted value is either top 10% or bottom 10%. Run SHAP to extract #1 reason for each observation in the top/bottom 10%.\n",
    "\n",
    "E5. Look for any cases where age, represented_by is the #1 factor for the bail_amount. These could be interesting cases to highlight\n",
    "\n",
    "E6. Word cloud of the terms - this could take some work I'm not too familiar w/ this\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### E1: Correlation Matrix \n",
    "Can we use Mutual Information ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I did check this in external tools and prove that they are independent - I just need to find time to code this in python and make a nice graphic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### E2: Feature Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>charge</td>\n",
       "      <td>0.630151</td>\n",
       "      <td>0.032533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>filed_hour_of_day</td>\n",
       "      <td>0.202640</td>\n",
       "      <td>0.039140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age</td>\n",
       "      <td>0.081307</td>\n",
       "      <td>0.004273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bail_status</td>\n",
       "      <td>0.068642</td>\n",
       "      <td>0.024312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>represented_by</td>\n",
       "      <td>0.064173</td>\n",
       "      <td>0.008351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>filed_day_of_week</td>\n",
       "      <td>0.031641</td>\n",
       "      <td>0.003237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature    weight       std\n",
       "0             charge  0.630151  0.032533\n",
       "1  filed_hour_of_day  0.202640  0.039140\n",
       "2                age  0.081307  0.004273\n",
       "3        bail_status  0.068642  0.024312\n",
       "4     represented_by  0.064173  0.008351\n",
       "5  filed_day_of_week  0.031641  0.003237"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "x = train.drop([TARGET_VARIABLE_NAME, HOLDOUT_INDICATOR_NAME], axis=1)\n",
    "y = train[TARGET_VARIABLE_NAME]\n",
    "\n",
    "estimator = final_pipe.named_steps['final_model']\n",
    "imputer = final_pipe.named_steps['preprocessor']\n",
    "\n",
    "x2 = imputer.transform(x)\n",
    "\n",
    "perm = PermutationImportance(estimator, random_state=1, cv=None)\n",
    "\n",
    "perm.fit(x2, y)\n",
    "\n",
    "features = list(x.columns)\n",
    "\n",
    "eli5.explain_weights_df(perm, feature_names = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to make a better chart here where we normalize max weight = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### E3: Feature Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### E4. Feature Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### E5. Specific Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### E6. Term Frequncy/ Word Cloud?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
